<!DOCTYPE html>
<html lang="ko">
  <head>
    <meta charset="UTF-8" />
    <title>ë…¼ìˆ  ìë™ í’€ì´ í…ŒìŠ¤íŠ¸</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <style>
      body {
        font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI",
          sans-serif;
        margin: 0;
        padding: 16px;
        box-sizing: border-box;
      }
      .row {
        display: flex;
        gap: 8px;
        margin-bottom: 8px;
        align-items: center;
      }
      video {
        width: 100%;
        max-height: 300px;
        background: #000;
      }
      textarea {
        width: 100%;
        min-height: 120px;
        box-sizing: border-box;
      }
      button {
        padding: 8px 14px;
        font-size: 14px;
        cursor: pointer;
      }
      #status {
        font-size: 13px;
        color: #444;
        min-height: 18px;
      }
      #canvas {
        display: none;
      }
    </style>
  </head>
  <body>
    <h2>ì—°ì„¸ëŒ€ ë…¼ìˆ  ìë™ OCR í…ŒìŠ¤íŠ¸</h2>

    <div class="row">
      <video id="video" autoplay playsinline></video>
    </div>

    <canvas id="canvas"></canvas>

    <div class="row">
      <button id="shutter">ğŸ“¸ ì´¬ì˜</button>
      <button id="solve">ğŸ“ í’€ê¸°</button>
    </div>

    <div id="status"></div>

    <h3>OCR ê²°ê³¼</h3>
    <textarea id="ocrResult" placeholder="ì—¬ê¸°ì— ì œì‹œë¬¸ OCR ê²°ê³¼ê°€ ëˆ„ì ë©ë‹ˆë‹¤."></textarea>

    <h3>AI ë‹µì•ˆ (í’€ì´ ê²°ê³¼)</h3>
    <textarea id="answerResult" placeholder="solve í•¨ìˆ˜ ì‘ë‹µì„ ì—¬ê¸°ì— í‘œì‹œ"></textarea>

    <script>
      const video = document.getElementById("video");
      const canvas = document.getElementById("canvas");
      const shutterBtn = document.getElementById("shutter");
      const solveBtn = document.getElementById("solve");
      const statusEl = document.getElementById("status");
      const ocrResultEl = document.getElementById("ocrResult");
      const answerResultEl = document.getElementById("answerResult");

      let currentPage = 1;
      const maxPages = 10; // í•„ìš”í•˜ë©´ ì¡°ì ˆ

      async function startCamera() {
        try {
          const stream = await navigator.mediaDevices.getUserMedia({
            video: { facingMode: "environment" },
            audio: false,
          });
          video.srcObject = stream;
          await video.play();
          statusEl.textContent = "ì¹´ë©”ë¼ ì¤€ë¹„ ì™„ë£Œ";
        } catch (e) {
          statusEl.textContent = "ì¹´ë©”ë¼ ì‹œì‘ ì‹¤íŒ¨: " + e.message;
        }
      }

      async function captureAndOcr() {
        if (!video.videoWidth || !video.videoHeight) {
          statusEl.textContent =
            "ì˜ìƒ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤. 1~2ì´ˆ ë’¤ì— ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.";
          return;
        }

        // ë¹„ë””ì˜¤ í”„ë ˆì„ì„ ê·¸ëŒ€ë¡œ ìº”ë²„ìŠ¤ì— ë³µì‚¬
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        const ctx = canvas.getContext("2d");
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

        // base64 ë°ì´í„° ë§Œë“¤ê¸°
        const dataUrl = canvas.toDataURL("image/jpeg", 0.9);

        statusEl.textContent = `í˜ì´ì§€ ${currentPage} OCR ìš”ì²­ ì¤‘...`;

        try {
          const res = await fetch("/.netlify/functions/ocr", {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({
              imageBase64: dataUrl,
              pageIndex: currentPage,
            }),
          });

          const json = await res.json().catch(() => null);

          if (!res.ok || !json || !json.ok) {
            const msg =
              (json && json.message) ||
              (json && json.error) ||
              res.statusText ||
              "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜";

            statusEl.textContent = "ì‹¤íŒ¨: " + msg;
            console.error("OCR error detail:", json);
            return;
          }

          const prev = ocrResultEl.value || "";
          ocrResultEl.value =
            prev +
            `\n\n[í˜ì´ì§€ ${json.pageIndex}]-------------------\n` +
            (json.ocrText || "");

          statusEl.textContent = `í˜ì´ì§€ ${currentPage} OCR ì™„ë£Œ`;

          if (currentPage < maxPages) {
            currentPage += 1;
          }
        } catch (e) {
          statusEl.textContent = "ìš”ì²­ ì‹¤íŒ¨: " + e.message;
          console.error(e);
        }
      }

      async function solveNow() {
        const text = ocrResultEl.value.trim();
        if (!text) {
          statusEl.textContent = "ë¨¼ì € OCRì„ ì™„ë£Œí•´ì£¼ì„¸ìš”.";
          return;
        }

        statusEl.textContent = "AI í’€ì´ ìš”ì²­ ì¤‘...";

        try {
          const res = await fetch("/.netlify/functions/solve", {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({
              text, // solve.jsì—ì„œ ì´ í•„ë“œëª…ì„ ì‚¬ìš©í•˜ë„ë¡ ë§ì¶°ì¤˜
            }),
          });

          const json = await res.json().catch(() => null);

          if (!res.ok || !json) {
            const msg =
              (json && json.message) ||
              (json && json.error) ||
              res.statusText ||
              "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜";
            statusEl.textContent = "í’€ì´ ì‹¤íŒ¨: " + msg;
            console.error("solve error detail:", json);
            return;
          }

          // ì‘ë‹µ êµ¬ì¡°ëŠ” ë„¤ solve.jsì— ë§ê²Œ ìˆ˜ì • ê°€ëŠ¥
          const answer = json.answer || json.result || JSON.stringify(json);
          answerResultEl.value = answer;

          statusEl.textContent = "í’€ì´ ì™„ë£Œ";
        } catch (e) {
          statusEl.textContent = "í’€ì´ ìš”ì²­ ì‹¤íŒ¨: " + e.message;
          console.error(e);
        }
      }

      shutterBtn.addEventListener("click", captureAndOcr);
      solveBtn.addEventListener("click", solveNow);

      window.addEventListener("load", startCamera);
    </script>
  </body>
</html>
