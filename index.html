<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8" />
  <title>answer-site Reading ì—°êµ¬ìš© (ì¹´ë©”ë¼ + OCR + í’€ì´)</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    * { box-sizing: border-box; }
    body {
      font-family: system-ui, -apple-system, BlinkMacSystemFont, sans-serif;
      background: #111;
      color: #eee;
      margin: 0;
      padding: 16px;
    }
    h1 { font-size: 1.4rem; margin-bottom: 0.5rem; }
    h2 { font-size: 1.1rem; margin: 12px 0 4px; }
    p  { font-size: 0.9rem; color: #bbb; margin: 4px 0; }
    .section { margin-top: 16px; }
    video, img {
      width: 100%;
      max-width: 480px;
      background: #000;
      border-radius: 10px;
      display: block;
      margin-top: 12px;
    }
    button {
      margin-top: 8px;
      padding: 10px 16px;
      font-size: 15px;
      border-radius: 999px;
      border: none;
      background: #2a2a2a;
      color: #fff;
      cursor: pointer;
    }
    button:active { opacity: 0.8; }
    .buttons {
      margin-top: 8px;
      display: flex;
      gap: 8px;
      flex-wrap: wrap;
    }
    #status, #solveStatus {
      margin-top: 8px;
      font-size: 0.85rem;
      color: #ccc;
      white-space: pre-line;
    }
    textarea {
      width: 100%;
      max-width: 600px;
      border-radius: 8px;
      border: 1px solid #444;
      background: #181818;
      color: #eee;
      padding: 8px;
      font-size: 0.9rem;
      margin-top: 4px;
    }
    label {
      display: block;
      font-size: 0.85rem;
      color: #aaa;
      margin-top: 8px;
    }
    select {
      margin-top: 4px;
      padding: 6px 10px;
      border-radius: 8px;
      border: 1px solid #444;
      background: #181818;
      color: #eee;
      font-size: 0.9rem;
    }
    #answerArea {
      font-size: 2rem;
      font-weight: bold;
      margin-top: 8px;
    }
  </style>
</head>
<body>
  <h1>ğŸ“š Reading ì—°êµ¬ìš©: ì¹´ë©”ë¼ + OCR + ìë™ í’€ì´(1~5)</h1>
  <p>
    ì´ ë²„ì „ì€ <b>Reading ì§€ë¬¸ + ë¬¸ì œ êµ¬ì¡°</b>ë¥¼ ì—°êµ¬ìš©ìœ¼ë¡œ ë§ì¶˜ ê±°ì•¼.<br />
    1) ì§€ë¬¸ì„ í•œ ë²ˆë§Œ ìº¡ì²˜í•´ì„œ ì €ì¥í•˜ê³ ,<br />
    2) ê°™ì€ ì§€ë¬¸ì— ëŒ€í•œ ì—¬ëŸ¬ ë¬¸ì œë¥¼ ë”°ë¡œ ìº¡ì²˜í•´ì„œ í’€ ìˆ˜ ìˆìŒ.
  </p>

  <!-- ì¹´ë©”ë¼ ì˜ì—­ -->
  <div class="section">
    <h2>1. ì¹´ë©”ë¼</h2>
    <button id="startBtn">ì¹´ë©”ë¼ ì¼œê¸°</button>
    <div id="status">ëŒ€ê¸° ì¤‘...</div>
    <video id="video" autoplay playsinline muted></video>

    <div class="buttons">
      <!-- ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©: í˜„ì¬ í™”ë©´ì„ ë¬¸ì œë¡œ ë³´ê³  ê³§ë°”ë¡œ í’€ì´ -->
      <button id="captureOcrSolveBtn">ğŸ“¸ (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸) í˜„ì¬ í™”ë©´ ìº¡ì²˜ + OCR + í’€ì´</button>
    </div>
  </div>

  <!-- ìº¡ì²˜ëœ ì´ë¯¸ì§€ -->
  <div class="section">
    <h2>2. í˜„ì¬ ìº¡ì²˜ëœ ì´ë¯¸ì§€ (ì¤‘ì•™ 80% ì‚¬ìš©)</h2>
    <img id="capturedImage" alt="ìº¡ì²˜ëœ í™”ë©´" />
  </div>

  <!-- Reading ì—°êµ¬ìš© í…ìŠ¤íŠ¸ -->
  <div class="section">
    <h2>3. Reading ì—°êµ¬ìš© í…ìŠ¤íŠ¸</h2>

    <!-- ì§€ë¬¸ -->
    <label for="passageText">ì§€ë¬¸ (Passage) â€“ ê°™ì€ ì§€ë¬¸ì´ë©´ í•œ ë²ˆë§Œ OCRí•´ì„œ ì—¬ê¸° ì €ì¥</label>
    <textarea id="passageText" rows="8"
      placeholder="ì§€ë¬¸ ì „ì²´ë¥¼ í•œ ë²ˆë§Œ ìº¡ì²˜í•´ì„œ OCR ê²°ê³¼ë¥¼ ì—¬ê¸° ì €ì¥í•©ë‹ˆë‹¤."></textarea>
    <button id="capturePassageBtn">ğŸ“š í˜„ì¬ í™”ë©´ì„ ì§€ë¬¸ìœ¼ë¡œ OCR (í•œ ë²ˆë§Œ)</button>
    <p style="font-size:0.8rem;">
      Reading ì‹¤ì œ êµ¬ì¡°ì²˜ëŸ¼, ì§€ë¬¸ì€ í•œ ë²ˆë§Œ ìº¡ì²˜í•˜ê³ <br />
      ê°™ì€ ì§€ë¬¸ì— ëŒ€í•œ ì—¬ëŸ¬ ë¬¸ì œë¥¼ ì•„ë˜ì—ì„œ ë”°ë¡œ ìº¡ì²˜í•´ì„œ í’€ ìˆ˜ ìˆê²Œ í•˜ëŠ” êµ¬ì¡°ì•¼.
    </p>

    <!-- ë¬¸ì œ -->
    <label for="questionText">ë¬¸ì œ + ë³´ê¸° (Question + Options)</label>
    <textarea id="questionText" rows="8"
      placeholder="ë¬¸ì œ 1ê°œì™€ ë³´ê¸°(1~5)ë¥¼ ìº¡ì²˜í•˜ê±°ë‚˜ ì§ì ‘ ë¶™ì—¬ë„£ìŠµë‹ˆë‹¤."></textarea>

    <div class="buttons">
      <button id="captureOcrBtn">ğŸ“¸ í˜„ì¬ í™”ë©´ì„ ë¬¸ì œë¡œ OCR</button>
      <button id="solveBtn">ì´ í…ìŠ¤íŠ¸ë¡œ AI í’€ì´ (1~5)</button>
    </div>

    <!-- ë¬¸ì œ ìœ í˜• íƒœê·¸ -->
    <label for="qTypeSelect">ë¬¸ì œ ìœ í˜• (ì—°êµ¬ìš© íƒœê·¸)</label>
    <select id="qTypeSelect">
      <option value="reading_general">ì¼ë°˜ ê°ê´€ì‹ (ê¸°ë³¸ê°’)</option>
      <option value="vocab">Vocabulary (ë‹¨ì–´ ì˜ë¯¸)</option>
      <option value="reference">Reference (ì§€ì‹œì–´)</option>
      <option value="factual">Factual (ì‚¬ì‹¤ ì •ë³´)</option>
      <option value="negative">Negative Factual</option>
      <option value="inference">Inference (ì¶”ë¡ )</option>
      <option value="function">Function / Purpose</option>
      <option value="simplification">Sentence Simplification</option>
      <option value="insert">Insert Sentence</option>
      <option value="summary">Summary (ìš”ì•½)</option>
      <option value="table">Table / Organization</option>
    </select>

    <div id="solveStatus">ì•„ì§ í’€ì´ ìš”ì²­ ì—†ìŒ</div>
  </div>

  <!-- ì •ë‹µ í‘œì‹œ -->
  <div class="section">
    <h2>4. AI ì •ë‹µ (1~5 ë²ˆí˜¸)</h2>
    <div id="answerArea">ì•„ì§ ì •ë‹µ ì—†ìŒ</div>
  </div>

  <!-- ìˆ¨ê²¨ì§„ ìº”ë²„ìŠ¤ -->
  <canvas id="canvas" style="display:none;"></canvas>

  <!-- Tesseract.js (OCR ë¼ì´ë¸ŒëŸ¬ë¦¬) -->
  <script src="https://unpkg.com/tesseract.js@5/dist/tesseract.min.js"></script>

  <!-- ì•± ë¡œì§ + Firebase ì—°ë™ -->
  <script type="module">
    import { initializeApp }   from "https://www.gstatic.com/firebasejs/11.0.1/firebase-app.js";
    import { getDatabase, ref, onValue, set } from "https://www.gstatic.com/firebasejs/11.0.1/firebase-database.js";

    // ğŸ”¹ ë„¤ Firebase ì„¤ì • (ì´ë¯¸ í™•ì¸í•œ ê°’)
    const firebaseConfig = {
      apiKey: "AIzaSyAvjpHfmbuHQq3ZeV6mNKQFI9LsnX-vf68",
      authDomain: "answer-site-p2p.firebaseapp.com",
      databaseURL: "https://answer-site-p2p-default-rtdb.asia-southeast1.firebasedatabase.app",
      projectId: "answer-site-p2p",
      storageBucket: "answer-site-p2p.firebasestorage.app",
      messagingSenderId: "364227113735",
      appId: "1:364227113735:web:b18355cf0b16454663cba2",
      measurementId: "G-C8MRHK5ZGS"
    };

    const ROOM_ID = "room1"; // íœ´ëŒ€í°/ì›ê²© ë‘˜ ë‹¤ ë™ì¼í•˜ê²Œ ì‚¬ìš©

    const app = initializeApp(firebaseConfig);
    const db  = getDatabase(app);
    const commandRef = ref(db, `rooms/${ROOM_ID}/command`);
    const resultRef  = ref(db, `rooms/${ROOM_ID}/result`);

    // --- DOM ìš”ì†Œ ---
    const startBtn   = document.getElementById('startBtn');
    const statusEl   = document.getElementById('status');
    const video      = document.getElementById('video');

    const canvas         = document.getElementById('canvas');
    const capturedImage  = document.getElementById('capturedImage');
    const captureOcrSolveBtn = document.getElementById('captureOcrSolveBtn');

    const passageTextEl   = document.getElementById('passageText');
    const capturePassageBtn = document.getElementById('capturePassageBtn');
    const questionTextEl  = document.getElementById('questionText');
    const captureOcrBtn   = document.getElementById('captureOcrBtn');
    const qTypeSelect     = document.getElementById('qTypeSelect');
    const solveBtn        = document.getElementById('solveBtn');
    const solveStatus     = document.getElementById('solveStatus');
    const answerArea      = document.getElementById('answerArea');

    let stream = null;
    let lastAnswer = null;
    let passageText = '';      // ì§€ë¬¸ í…ìŠ¤íŠ¸ ìºì‹œ

    // ì›ê²© ìš”ì²­ ì²˜ë¦¬ìš©
    let lastRemoteRequestId = null;
    let remoteProcessing = false;

    // 1) ì¹´ë©”ë¼ ì¼œê¸°
    async function startCamera() {
      statusEl.textContent = 'ë²„íŠ¼ ëˆŒë¦¼ â†’ ì¹´ë©”ë¼ ìš”ì²­ ì¤‘...';

      try {
        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
          statusEl.textContent = 'ì´ ë¸Œë¼ìš°ì €ëŠ” getUserMediaë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.';
          return;
        }

        if (stream) {
          statusEl.textContent = 'ì´ë¯¸ ì¹´ë©”ë¼ê°€ ì¼œì ¸ ìˆìŠµë‹ˆë‹¤.';
          return;
        }

        stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: 'environment' },
          audio: false,
        });

        video.srcObject = stream;

        video.addEventListener(
          'loadedmetadata',
          () => {
            statusEl.textContent =
              'ì¹´ë©”ë¼ ì—°ê²° ì„±ê³µ âœ…\\nì‹¤ì œ í•´ìƒë„: ' +
              video.videoWidth + ' x ' + video.videoHeight;
          },
          { once: true }
        );
      } catch (err) {
        console.error(err);
        statusEl.textContent =
          'ì¹´ë©”ë¼ ì˜¤ë¥˜ âŒ\\n' +
          'ë©”ì‹œì§€: ' + err.name + ' - ' + err.message +
          '\\në¸Œë¼ìš°ì € ì£¼ì†Œì°½ ì˜† ìë¬¼ì‡  ì•„ì´ì½˜ì—ì„œ ì¹´ë©”ë¼ ê¶Œí•œì´ ì°¨ë‹¨ë¼ ìˆì§€ ì•Šì€ì§€ í™•ì¸í•´.';
        alert('ì¹´ë©”ë¼ ì˜¤ë¥˜: ' + err.name + '\\n' + err.message);
      }
    }

    startBtn.addEventListener('click', startCamera);

    // 2) í˜„ì¬ í”„ë ˆì„ì„ ìº”ë²„ìŠ¤/ì´ë¯¸ì§€ë¡œ ìº¡ì²˜ (ìœ„/ì•„ë˜ 10% ì˜ë¼ì„œ ì¤‘ì•™ 80%ë§Œ ì‚¬ìš©)
    function captureToCanvasAndImage() {
      if (!video.videoWidth || !video.videoHeight) {
        alert('ì¹´ë©”ë¼ê°€ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 1~2ì´ˆ ë’¤ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.');
        return false;
      }

      const cropTop    = Math.floor(video.videoHeight * 0.1);
      const cropHeight = Math.floor(video.videoHeight * 0.8);

      canvas.width  = video.videoWidth;
      canvas.height = cropHeight;

      const ctx = canvas.getContext('2d');
      ctx.drawImage(
        video,
        0, cropTop, video.videoWidth, cropHeight,
        0, 0, canvas.width, canvas.height
      );

      const dataUrl = canvas.toDataURL('image/png');
      capturedImage.src = dataUrl;

      return true;
    }

    // 3) OCR í…ìŠ¤íŠ¸ ì •ë¦¬ (URL/ì‹œê°„/ì €ì‘ê¶Œ ê°™ì€ ë…¸ì´ì¦ˆ ì œê±°)
    function cleanOcrText(raw) {
      if (!raw) return '';
      return raw
        .split('\\n')
        .map(line => line.trim())
        .filter(line => line.length > 0)
        .filter(line => !line.match(/https?:\\/\\//i))   // URL ì œê±°
        .filter(line => !line.match(/\\d{1,2}:\\d{2}/))  // 12:34 ê°™ì€ ì‹œê°„ ì œê±°
        .filter(line => !line.match(/Copyright|Â©/i))     // ì €ì‘ê¶Œ ë¼ì¸ ì œê±°
        .join('\\n');
    }

    // 4) ì§€ë¬¸ ìº¡ì²˜ + OCR (í•œ ë²ˆë§Œ í•˜ë©´ ë¨)
    async function capturePassageOcr() {
      const ok = captureToCanvasAndImage();
      if (!ok) return;

      statusEl.textContent = 'ì§€ë¬¸ OCR ì²˜ë¦¬ ì¤‘...';
      try {
        const result = await Tesseract.recognize(canvas, 'eng', { logger: m => console.log(m) });
        const raw    = (result.data.text || '').trim();
        const cleaned   = cleanOcrText(raw);
        const finalText = cleaned || raw;

        passageText = finalText;
        passageTextEl.value = finalText;
        statusEl.textContent = 'ì§€ë¬¸ OCR ì™„ë£Œ. ì´ì œ ê°™ì€ ì§€ë¬¸ì— ëŒ€í•œ ë¬¸ì œë“¤ì„ ì•„ë˜ì—ì„œ ìº¡ì²˜í•´ì„œ í’€ ìˆ˜ ìˆìŠµë‹ˆë‹¤.';
      } catch (err) {
        console.error(err);
        statusEl.textContent = 'ì§€ë¬¸ OCR ì˜¤ë¥˜: ' + err.message;
        alert('ì§€ë¬¸ OCR ì˜¤ë¥˜: ' + err.message);
      }
    }

    capturePassageBtn.addEventListener('click', capturePassageOcr);

    // 5) ë¬¸ì œ ìº¡ì²˜ + OCRë§Œ
    async function captureQuestionOcr() {
      const ok = captureToCanvasAndImage();
      if (!ok) return;

      statusEl.textContent   = 'ë¬¸ì œ OCR ì²˜ë¦¬ ì¤‘...';
      questionTextEl.value   = '';
      answerArea.textContent = 'ì•„ì§ ì •ë‹µ ì—†ìŒ';
      solveStatus.textContent = 'ì•„ì§ í’€ì´ ìš”ì²­ ì—†ìŒ';
      lastAnswer             = null;

      try {
        const result = await Tesseract.recognize(canvas, 'eng', { logger: m => console.log(m) });
        const raw    = (result.data.text || '').trim();
        const cleaned   = cleanOcrText(raw);
        const finalText = cleaned || raw;

        questionTextEl.value = finalText;
        statusEl.textContent = 'ë¬¸ì œ OCR ì™„ë£Œ. í•„ìš”í•˜ë©´ í…ìŠ¤íŠ¸ë¥¼ ì •ë¦¬í•œ ë’¤, í’€ì´ ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”.';
      } catch (err) {
        console.error(err);
        statusEl.textContent = 'ë¬¸ì œ OCR ì˜¤ë¥˜: ' + err.message;
        alert('ë¬¸ì œ OCR ì˜¤ë¥˜: ' + err.message);
      }
    }

    captureOcrBtn.addEventListener('click', captureQuestionOcr);

    // 6) ìº¡ì²˜ + OCR + ë°”ë¡œ í’€ì´ (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ / ì›ê²©ìš© ê³µí†µ)
    async function captureOcrAndSolve(sendRemote = false, requestId = null) {
      const ok = captureToCanvasAndImage();
      if (!ok) return;

      statusEl.textContent   = 'ë¬¸ì œ OCR ì²˜ë¦¬ ì¤‘...';
      questionTextEl.value   = '';
      answerArea.textContent = 'í’€ì´ ì¤€ë¹„ ì¤‘...';
      solveStatus.textContent = 'AI í’€ì´ ëŒ€ê¸° ì¤‘...';
      lastAnswer             = null;

      try {
        const result = await Tesseract.recognize(canvas, 'eng', { logger: m => console.log(m) });
        const raw    = (result.data.text || '').trim();
        const cleaned   = cleanOcrText(raw);
        const finalText = cleaned || raw;

        questionTextEl.value = finalText;
        statusEl.textContent = 'ë¬¸ì œ OCR ì™„ë£Œ, AI í’€ì´ ì¤‘...';

        await solveQuestion(finalText, { sendRemote, requestId });
      } catch (err) {
        console.error(err);
        statusEl.textContent = 'OCR/í’€ì´ ì¤‘ ì˜¤ë¥˜: ' + err.message;
        alert('OCR/í’€ì´ ì¤‘ ì˜¤ë¥˜: ' + err.message);
      }
    }

    captureOcrSolveBtn.addEventListener('click', () => captureOcrAndSolve(false, null));

    // 7) í…ìŠ¤íŠ¸ë¡œë§Œ AI í’€ì´
    async function solveQuestionFromTextarea() {
      const text = questionTextEl.value.trim();
      if (!text) {
        alert('ë³´ë‚¼ ë¬¸ì œ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.');
        return;
      }
      solveStatus.textContent = 'AI í’€ì´ ì¤‘...';
      answerArea.textContent  = '...';
      await solveQuestion(text, { sendRemote: false, requestId: null });
    }

    solveBtn.addEventListener('click', solveQuestionFromTextarea);

    // 8) ì‹¤ì œ AI í˜¸ì¶œ (Netlify Functionsì˜ solve.js)
    async function solveQuestion(questionText, options = {}) {
      const { sendRemote = false, requestId = null } = options;

      const section = 'reading';  // ì§€ê¸ˆì€ Reading ì—°êµ¬ìš©ë§Œ ì‚¬ìš©
      const qType   = qTypeSelect ? qTypeSelect.value : 'reading_general';
      const passage = (passageTextEl.value || '').trim() || null;

      try {
        const res = await fetch('/.netlify/functions/solve', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            section,
            qType,
            passage,
            question: questionText
          }),
        });

        if (!res.ok) {
          throw new Error('ì„œë²„ ì˜¤ë¥˜: ' + res.status);
        }

        const data = await res.json();
        const finalAnswer = data.answer || '';

        lastAnswer = finalAnswer;

        answerArea.textContent  = finalAnswer || 'ì‘ë‹µ í¬ë§· ì˜¤ë¥˜';
        solveStatus.textContent = 'í’€ì´ ì™„ë£Œ.';

        if (sendRemote) {
          await set(resultRef, {
            requestId: requestId || null,
            section,
            qType,
            passageSnippet: passage ? passage.slice(0, 200) : null,
            text: questionText,
            answer: finalAnswer,
            image: capturedImage.src || null,
            updatedAt: Date.now()
          });
        }
      } catch (err) {
        console.error(err);
        solveStatus.textContent = 'í’€ì´ ì˜¤ë¥˜: ' + err.message;
        alert('í’€ì´ ì˜¤ë¥˜: ' + err.message);
      }
    }

    // 9) Firebaseì—ì„œ ì›ê²© ìº¡ì²˜ ëª…ë ¹ ë“£ê¸° (remote.html â†’ íœ´ëŒ€í°)
    onValue(commandRef, async (snapshot) => {
      const cmd = snapshot.val();
      if (!cmd) return;
      if (cmd.type !== 'capture') return;

      const reqId = cmd.requestId || null;

      // ê°™ì€ ìš”ì²­ ì—¬ëŸ¬ ë²ˆ ì²˜ë¦¬í•˜ì§€ ì•Šë„ë¡
      if (lastRemoteRequestId && reqId && lastRemoteRequestId === reqId) {
        return;
      }
      lastRemoteRequestId = reqId || Date.now();

      if (remoteProcessing) return;
      remoteProcessing = true;

      statusEl.textContent = `ì›ê²© ìº¡ì²˜ ìš”ì²­ ìˆ˜ì‹  (ID: ${reqId || 'ì—†ìŒ'}) â†’ ì²˜ë¦¬ ì¤‘...`;
      try {
        await captureOcrAndSolve(true, reqId);
      } finally {
        remoteProcessing = false;
      }
    });
  </script>
</body>
</html>
