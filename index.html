// netlify/functions/solve.js
// --------------------------------------
// 역할: 편입 영어 객관식 기출 "정답만" 생성하는 함수
// 입력: { ocrText: string, page?: number }
// 출력: { ok: true, text: "1: 4\n2: 3\n...", debug: {...} }
//
// 환경변수 (Netlify):
// - OPENROUTER_API_KEY  (필수)
// - MODEL_NAME          (선택, 기본: "openai/gpt-4.1")
// - TEMPERATURE         (선택, 기본: 0.1)
// - STOP_TOKEN          (선택, 기본: "XURTH")

function json(statusCode, obj) {
  return {
    statusCode,
    headers: {
      "Content-Type": "application/json",
      "Access-Control-Allow-Origin": "*",
    },
    body: JSON.stringify(obj),
  };
}

/**
 * OpenRouter 호출
 */
async function callOpenRouter({ apiKey, model, temperature, stopToken, page, ocrText }) {
  const systemPrompt = `
너는 "편입영어 객관식 기출 채점/정답키 생성" 전용 AI다.

[역할]
- 입력: 한국 대학교 편입 영어 객관식 시험지의 OCR 텍스트(부분 / 여러 페이지 중 일부일 수 있음).
- 출력: 보이는 문항번호에 대한 "정답번호만" (한 줄에 하나씩)

[최우선 목표]
1) 오답 최소화
2) 문항 누락 0: OCR 텍스트에서 '보이는 문항번호'는 전부 답을 출력한다.
3) 정답 형식 고정:
   - 각 줄: "문항번호: 선택지번호"
     예: "1: 4", "12: 2"
   - 선택지번호는 1~5 중 하나 (①~⑤, A~E 가 OCR 상에 섞여 있어도 최종 출력은 1~5 번호로 통일)
4) 불확실하면 해당 줄 끝에 "?"만 붙인다. (예: "13: 2?")
5) 마지막 줄에 "UNSURE: x y z" 형식으로 불확실한 문항번호를 공백 또는 쉼표로 나열한다.
   예: "UNSURE: 13 24" 또는 "UNSURE: 13, 24"
6) 그 외 설명/해설/머리말/마크다운/공백 라인 등은 절대 출력하지 않는다.

[해석 규칙]
- 문항번호 패턴 예:
  - "1.", "1 )", "1 )", "1번", "(1)", "[1]" 등 → 1번
- 선택지 표기 예:
  - "① ② ③ ④ ⑤" → 1~5
  - "A. B. C. D. E." 또는 "A)" → A~E → 1~5로 변환해서 출력
- 한 지문에 문제 2개 이상(예: 21, 22)이 붙어 있어도,
  - OCR 텍스트 안에서 문제/선지의 범위를 추론해서 각각의 정답을 결정한다.
- 지문/선지가 페이지에 나뉘어 있을 수 있다는 점을 고려하되,
  - 현재 OCR 텍스트에 보이는 문항만 처리한다.
  - 지문이 반만 보이고 선지가 전혀 안 보이면, "??"로 찍지 말고 불확실로 처리하고 "?" + UNSURE에 포함시킨다.

[출력 예시 1]
1: 4
2: 3
3: 2?
UNSURE: 3

[출력 예시 2]
20: 3
21: 1
22: 2
UNSURE:
(불확실한 문항 없으면 UNSURE 뒤는 비워도 됨)
  `.trim();

  const userPrompt = `
다음은 한국 대학교 편입 영어 객관식 시험지의 OCR 텍스트다.

페이지 번호(참고용): ${page}

[OCR 시작]
${ocrText}
[OCR 끝]

위 내용을 기반으로:
- 보이는 모든 문항번호에 대해 "문항번호: 정답번호" 형식으로만 출력해라.
- 선택지는 반드시 1~5 중 하나로만 출력해라.
- 불확실한 문항은 "?"를 붙이고, 마지막 줄에 "UNSURE: ..."로 번호만 모아서 다시 한 번 표시해라.
- 그 외 어떤 문장도 쓰지 마라.
  `.trim();

  const body = {
    model,
    temperature,
    stop: [stopToken],
    messages: [
      { role: "system", content: systemPrompt },
      { role: "user", content: userPrompt },
    ],
  };

  // Netlify Node 18+ 에는 fetch 내장이라 별도 node-fetch import 필요 없음
  const res = await fetch("https://openrouter.ai/api/v1/chat/completions", {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      Authorization: `Bearer ${apiKey}`,
    },
    body: JSON.stringify(body),
  });

  if (!res.ok) {
    const text = await res.text().catch(() => "");
    throw new Error(`OpenRouter HTTP ${res.status} ${res.statusText} - ${text}`);
  }

  const data = await res.json();
  const choice = data && data.choices && data.choices[0];
  const content = choice && choice.message && choice.message.content
    ? String(choice.message.content).trim()
    : "";

  return {
    raw: data,
    content,
    finishReason: choice && choice.finish_reason ? choice.finish_reason : null,
  };
}

/**
 * "31: 4" / "12: 2?" / "UNSURE: 13 24" 같은 라인 파싱
 */
function parseAnswerLines(text) {
  const lines = String(text || "").split(/\r?\n/);
  const answers = {};
  const questionNumbers = [];
  let unsure = [];

  for (const raw of lines) {
    const line = raw.trim();
    if (!line) continue;

    // UNSURE 라인
    const mUnsure = line.match(/^UNSURE\s*:\s*(.*)$/i);
    if (mUnsure) {
      const tail = mUnsure[1].trim();
      if (!tail) {
        unsure = [];
      } else {
        unsure = tail
          .split(/[,\s]+/)
          .map((x) => x.trim())
          .filter(Boolean)
          .map((x) => Number(x))
          .filter((n) => !Number.isNaN(n));
      }
      continue;
    }

    // "12: 3" 또는 "12-3" + optional '?'
    const m = line.match(/^(\d{1,3})\s*[:\-]\s*([A-Ea-e1-5])\s*\??$/);
    if (m) {
      const q = Number(m[1]);
      let a = String(m[2]).toUpperCase();

      // A~E를 1~5로 정규화
      const map = { A: "1", B: "2", C: "3", D: "4", E: "5" };
      if (map[a]) a = map[a];

      answers[q] = a;
      if (!questionNumbers.includes(q)) questionNumbers.push(q);
    }
  }

  questionNumbers.sort((a, b) => a - b);
  return { answers, questionNumbers, unsure };
}

/**
 * Netlify handler
 */
exports.handler = async (event) => {
  try {
    if (event.httpMethod !== "POST") {
      return json(405, { ok: false, error: "POST only" });
    }

    const apiKey = process.env.OPENROUTER_API_KEY;
    if (!apiKey) {
      return json(500, { ok: false, error: "OPENROUTER_API_KEY is not set" });
    }

    const model = process.env.MODEL_NAME || "openai/gpt-4.1"; // 너가 말한대로 4.1 기본
    const stopToken = process.env.STOP_TOKEN || "XURTH";
    const temperature = Number(
      process.env.TEMPERATURE === undefined ? 0.1 : process.env.TEMPERATURE
    );

    let body = {};
    try {
      body = JSON.parse(event.body || "{}");
    } catch {
      return json(400, { ok: false, error: "Invalid JSON body" });
    }

    const page = body.page ?? 1;
    const ocrText = String(body.ocrText || body.text || "");

    if (!ocrText.trim()) {
      return json(400, { ok: false, error: "ocrText is empty" });
    }

    let or;
    try {
      or = await callOpenRouter({
        apiKey,
        model,
        temperature,
        stopToken,
        page,
        ocrText,
      });
    } catch (e) {
      return json(500, {
        ok: false,
        error: "OpenRouter request failed",
        detail: e && e.message ? e.message : String(e || ""),
      });
    }

    const content = or.content || "";
    const parsed = parseAnswerLines(content);

    return json(200, {
      ok: true,
      text: content,
      debug: {
        page,
        model,
        finishReason: or.finishReason,
        questionNumbers: parsed.questionNumbers,
        answers: parsed.answers,
        unsure: parsed.unsure,
      },
    });
  } catch (e) {
    return json(500, {
      ok: false,
      error: "Unhandled error in solve function",
      detail: e && e.message ? e.message : String(e || ""),
    });
  }
};
