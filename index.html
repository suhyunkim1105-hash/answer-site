<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>answer-site | Capture & STT</title>

  <!-- Firebase -->
  <script src="https://www.gstatic.com/firebasejs/11.1.0/firebase-app-compat.js"></script>
  <script src="https://www.gstatic.com/firebasejs/11.1.0/firebase-database-compat.js"></script>

  <!-- Tesseract OCR -->
  <script src="https://cdn.jsdelivr.net/npm/tesseract.js@4.1.1/dist/tesseract.min.js"></script>

  <style>
    body { margin: 0; background: #000; overflow: hidden; }
    #video {
      width: 100vw;
      height: 100vh;
      object-fit: cover;
      background: #000;
    }
    #msg {
      position: absolute;
      top: 0; left: 0;
      color: #ffcccc;
      background: rgba(0,0,0,0.6);
      padding: 6px 10px;
      font-size: 12px;
      z-index: 10;
      white-space: pre-wrap;
      max-width: 100vw;
    }
    #zoomBar {
      position: absolute;
      bottom: 8px;
      left: 50%;
      transform: translateX(-50%);
      background: rgba(0,0,0,0.6);
      color: #fff;
      padding: 4px 8px;
      border-radius: 6px;
      font-size: 12px;
      z-index: 10;
      display: flex;
      align-items: center;
      gap: 6px;
    }
    #zoomSlider {
      width: 160px;
    }
  </style>
</head>
<body>

<div id="msg"></div>
<video id="video" autoplay playsinline></video>

<div id="zoomBar">
  <span>Zoom</span>
  <input id="zoomSlider" type="range" min="1" max="3" step="0.1" value="1">
  <span id="zoomValue">1.0×</span>
</div>

<script>
  // ---------------------- Firebase ----------------------
  const firebaseConfig = {
    apiKey: "AIzaSyAvjpHfmbuHQq3ZeV6mNKQFI9LsnX-vf68",
    authDomain: "answer-site-p2p.firebaseapp.com",
    databaseURL: "https://answer-site-p2p-default-rtdb.asia-southeast1.firebasedatabase.app",
    projectId: "answer-site-p2p",
    storageBucket: "answer-site-p2p.firebasestorage.app",
    messagingSenderId: "364227113735",
    appId: "1:364227113735:web:b18355cf0b16454663cba2",
    measurementId: "G-C8MRHK5ZGS"
  };
  firebase.initializeApp(firebaseConfig);
  const db = firebase.database();

  const video      = document.getElementById('video');
  const msg        = document.getElementById('msg');
  const zoomSlider = document.getElementById('zoomSlider');
  const zoomValue  = document.getElementById('zoomValue');

  let passageCache  = "";
  let questionCache = "";
  let sttCache      = "";
  let currentZoom   = 1.0;
  let videoTrack    = null;
  let zoomCap       = null;   // 카메라 자체 줌 지원 여부

  // ---------------------- Camera Init ----------------------
  async function startCamera() {
    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
      msg.textContent = "이 브라우저는 카메라를 지원하지 않습니다.";
      return;
    }

    const tries = [
      { audio: false, video: { facingMode: { exact: "environment" }, width: { ideal: 1920 }, height: { ideal: 1080 } } },
      { audio: false, video: { facingMode: "environment", width: { ideal: 1920 }, height: { ideal: 1080 } } },
      { audio: false, video: { facingMode: "environment", width: { ideal: 1280 }, height: { ideal: 720 } } },
      { audio: false, video: true }
    ];

    for (const c of tries) {
      try {
        const stream = await navigator.mediaDevices.getUserMedia(c);
        const tracks = stream.getVideoTracks();
        if (tracks && tracks[0]) {
          videoTrack = tracks[0];
          try {
            const caps = videoTrack.getCapabilities && videoTrack.getCapabilities();
            if (caps && typeof caps.zoom === "object") {
              zoomCap = caps.zoom;
            }
          } catch {}
        }
        video.srcObject = stream;
        msg.textContent = "카메라 준비됨";
        return;
      } catch (e) {
        console.warn("camera attempt failed", c, e);
      }
    }
    msg.textContent = "카메라 시작 실패. 권한/보안앱 설정 확인.";
  }
  startCamera();

  async function waitVideoReady() {
    if (video.videoWidth && video.videoHeight) return;
    await new Promise(resolve => {
      const t = setTimeout(resolve, 3000);
      video.addEventListener('loadedmetadata', () => {
        clearTimeout(t);
        resolve();
      }, { once: true });
    });
  }

  // ---------------------- Zoom Control ----------------------
  zoomSlider.addEventListener("input", () => {
    currentZoom = parseFloat(zoomSlider.value) || 1;
    zoomValue.textContent = currentZoom.toFixed(1) + "×";

    // 카메라가 진짜 zoom 지원하면 그걸 사용
    if (videoTrack && zoomCap) {
      const zMin = zoomCap.min ?? 1;
      const zMax = zoomCap.max ?? 3;
      const mapped = Math.min(zMax, Math.max(zMin, currentZoom));
      videoTrack.applyConstraints({ advanced: [{ zoom: mapped }] }).catch(() => {});
    }

    // 미리보기는 그냥 그대로 (이미 화면 전체라 CSS 줌은 굳이 안 함)
  });

  // ---------------------- OCR (zoom 반영: 중앙부 더 좁게 크롭) ----------------------
  async function captureAndOcr(target, lang, mode) {
    await waitVideoReady();

    const w = video.videoWidth;
    const h = video.videoHeight;
    if (!w || !h) {
      msg.textContent = "카메라 준비 안 됨";
      return;
    }

    // 기본 중앙 80%에서 시작, zoom 값에 따라 더 좁은 영역만 사용
    const baseFactor = 0.8;
    const zoomFactor = Math.max(1, currentZoom);
    const cropW = w * baseFactor / zoomFactor;
    const cropH = h * baseFactor / zoomFactor;
    const cropX = (w - cropW) / 2;
    const cropY = (h - cropH) / 2;

    const canvas = document.createElement('canvas');
    canvas.width  = cropW;
    canvas.height = cropH;
    const ctx = canvas.getContext('2d');
    ctx.drawImage(video, cropX, cropY, cropW, cropH, 0, 0, cropW, cropH);

    const tLang = (lang === "eng") ? "eng" : "eng+kor";
    msg.textContent = `OCR 중 (${tLang}, zoom=${currentZoom.toFixed(1)}×)...`;

    const { data } = await Tesseract.recognize(canvas.toDataURL('image/png'), tLang);
    const text = (data.text || "").trim();
    const confidence = (typeof data.confidence === "number")
      ? Math.round(data.confidence)
      : null;

    msg.textContent = confidence ? `OCR 완료 (${confidence}%)` : "OCR 완료";

    const now = Date.now();
    if (target === "passage") {
      passageCache = text;
      db.ref("p2p/state").update({
        mode,
        passage: passageCache,
        passageConf: confidence,
        updatedAt: now
      });
    } else if (target === "question") {
      questionCache = text;
      db.ref("p2p/state").update({
        mode,
        question: questionCache,
        questionConf: confidence,
        updatedAt: now
      });
    }
  }

  // ---------------------- STT ----------------------
  let recognition = null;
  let sttRunning  = false;

  function startSTT(mode) {
    if (sttRunning) return;
    const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SR) {
      msg.textContent = "STT 미지원 브라우저 (Chrome 권장)";
      return;
    }

    recognition = new SR();
    recognition.lang = "en-US";
    recognition.continuous = true;
    recognition.interimResults = true;

    sttCache = "";
    db.ref("p2p/state").update({
      mode,
      stt: "",
      sttUpdatedAt: Date.now()
    });

    recognition.onresult = (e) => {
      let interim = "";
      for (let i = e.resultIndex; i < e.results.length; i++) {
        const txt = e.results[i][0].transcript;
        if (e.results[i].isFinal) {
          sttCache += txt + "\n";
        } else {
          interim += txt;
        }
      }
      let full = (sttCache + "\n" + interim).trim();
      if (full.length > 4000) full = full.slice(-4000);
      sttCache = full;
      db.ref("p2p/state").update({
        mode,
        stt: sttCache,
        sttUpdatedAt: Date.now()
      });
      msg.textContent = "STT 수신 중...";
    };

    recognition.onstart = () => {
      sttRunning = true;
      msg.textContent = "STT 시작 (마이크)";
    };
    recognition.onend = () => {
      sttRunning = false;
      msg.textContent = "STT 종료";
    };

    recognition.start();
  }

  function stopSTT() {
    if (recognition && sttRunning) {
      recognition.stop();
    }
  }

  // ---------------------- Command Listener ----------------------
  let lastCmdTs = 0;

  function handleCommand(cmd) {
    const { type, mode, lang } = cmd;
    if (type === "capture_passage_new") {
      captureAndOcr("passage", lang, mode);
    } else if (type === "capture_question_new") {
      captureAndOcr("question", lang, mode);
    } else if (type === "stt_start") {
      startSTT(mode);
    } else if (type === "stt_stop") {
      stopSTT();
    } else if (type === "clear_state") {
      passageCache = "";
      questionCache = "";
      sttCache = "";
      db.ref("p2p/state").set({ mode, passage: "", question: "", stt: "", updatedAt: Date.now() });
      msg.textContent = "상태 초기화";
    }
  }

  db.ref("p2p/command").on("value", snap => {
    const cmd = snap.val();
    if (!cmd) return;
    if (!cmd.timestamp || cmd.timestamp <= lastCmdTs) return;
    lastCmdTs = cmd.timestamp;
    handleCommand(cmd);
  });
</script>
</body>
</html>
