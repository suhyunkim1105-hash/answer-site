<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>answer-site | Camera</title>
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

  <!-- Firebase -->
  <script src="https://www.gstatic.com/firebasejs/11.1.0/firebase-app-compat.js"></script>
  <script src="https://www.gstatic.com/firebasejs/11.1.0/firebase-database-compat.js"></script>

  <!-- Tesseract OCR -->
  <script src="https://unpkg.com/tesseract.js@4/dist/tesseract.min.js"></script>

  <style>
    * { box-sizing: border-box; }
    body {
      margin: 0;
      padding: 6px;
      background: #000;
      color: #fff;
      font-family: system-ui, -apple-system, BlinkMacSystemFont, sans-serif;
    }
    .wrap {
      width: 100%;
    }

    #videoContainer {
      position: relative;
      width: 100%;
      max-height: calc(100vh - 120px);
      overflow: hidden;
      background: #000;
      border-radius: 8px;
    }
    #video {
      width: 100%;
      height: auto;
      transform-origin: center center;
    }
    #overlayFrame {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      border: 2px solid rgba(0, 255, 0, 0.4);
      border-radius: 6px;
      pointer-events: none;
    }

    #controls {
      margin-top: 6px;
      font-size: 11px;
    }

    #statusLine {
      margin-bottom: 4px;
      color: #c4f1ff;
      white-space: nowrap;
      overflow: hidden;
      text-overflow: ellipsis;
    }

    .row {
      display: flex;
      align-items: center;
      gap: 6px;
    }
    .label {
      font-size: 11px;
      color: #aaa;
      white-space: nowrap;
    }
    #zoomRange {
      flex: 1 1 auto;
    }
    #btnOCRNow {
      flex: 0 0 auto;
      padding: 4px 8px;
      font-size: 11px;
      border-radius: 6px;
      border: 1px solid #666;
      background: #111;
      color: #f5f5f5;
      cursor: pointer;
    }
    #btnOCRNow:active {
      transform: scale(0.97);
    }
  </style>
</head>
<body>
<div class="wrap">
  <div id="videoContainer">
    <video id="video" autoplay playsinline></video>
    <div id="overlayFrame"></div>
  </div>

  <div id="controls">
    <div id="statusLine">ì¹´ë©”ë¼ ì¤€ë¹„ ì¤‘...</div>

    <div class="row">
      <span class="label">ë°°ìœ¨</span>
      <input id="zoomRange" type="range" min="1" max="3" step="0.05" value="1">
      <button id="btnOCRNow">ì§€ê¸ˆ ì¸ì‹</button>
    </div>
  </div>
</div>

<!-- ğŸ”¹ ë…¼ìˆ  ìë™ í’€ì´ í…ŒìŠ¤íŠ¸ UI -->
<div style="max-width: 960px; margin: 16px auto; padding: 10px; border: 1px solid #444; background:#111; border-radius:8px;">
  <h3 style="margin-top:0;">ë…¼ìˆ  ìë™ í’€ì´ í…ŒìŠ¤íŠ¸ (Netlify Functions â†’ solve)</h3>
  <p style="font-size:13px; color:#ccc;">
    OCRë¡œ ì¸ì‹ëœ <strong>ì „ì²´ ì œì‹œë¬¸ + [ë¬¸ì œ 1], [ë¬¸ì œ 2] í…ìŠ¤íŠ¸</strong>ë¥¼ ì•„ë˜ ì¹¸ì— ë¶™ì—¬ ë„£ê³ , [í’€ì´ ìš”ì²­]ì„ ëˆŒëŸ¬ ë´.
  </p>
  <textarea id="ocrTextInput" rows="8"
            style="width:100%; box-sizing:border-box; font-size:12px; font-family:monospace; background:#000; color:#fff; border-radius:4px; padding:6px;"></textarea>
  <button id="solveButton"
          style="margin-top:8px; padding:6px 10px; font-size:12px; border-radius:6px; border:1px solid #666; background:#222; color:#fff; cursor:pointer;">
    í’€ì´ ìš”ì²­
  </button>
  <h4 style="margin-top:14px;">ë‹µì•ˆ</h4>
  <pre id="answerOutput"
       style="white-space:pre-wrap; border:1px solid #333; padding:8px; min-height:100px; background:#000; color:#fff; border-radius:4px; font-size:12px;"></pre>
</div>

<script>
  // ---------------- Firebase ----------------
  const firebaseConfig = {
    apiKey: "AIzaSyAvjpHfmbuHQq3ZeV6mNKQFI9LsnX-vf68",
    authDomain: "answer-site-p2p.firebaseapp.com",
    databaseURL: "https://answer-site-p2p-default-rtdb.asia-southeast1.firebasedatabase.app",
    projectId: "answer-site-p2p",
    storageBucket: "answer-site-p2p.firebasestorage.app",
    messagingSenderId: "364227113735",
    appId: "1:364227113735:web:b18355cf0b16454663cba2",
    measurementId: "G-C8MRHK5ZGS"
  };
  firebase.initializeApp(firebaseConfig);
  const db = firebase.database();

  const video      = document.getElementById('video');
  const statusLine = document.getElementById('statusLine');
  const zoomRange  = document.getElementById('zoomRange');
  const btnOCRNow  = document.getElementById('btnOCRNow');

  // ì˜ì–´ë§Œ ì¸ì‹
  const OCR_LANG = "eng";

  // remote.htmlì—ì„œ ì„ íƒí•œ ëª¨ë“œ í‘œì‹œë§Œ
  let currentMode = "reading";
  db.ref("p2p/state/modeHint").on("value", snap => {
    const m = snap.val();
    if (m) {
      currentMode = m;
      if (statusLine.textContent.startsWith("ì¹´ë©”ë¼ ON")) {
        const match = statusLine.textContent.match(/\(.*?\)/);
        const resInfo = match ? ` ${match[0]} ` : " ";
        statusLine.textContent =
          `ì¹´ë©”ë¼ ON${resInfo}â€“ ëª¨ë“œ: ${currentMode} (í™”ë©´ ì•ˆì •ë˜ë©´ ìë™ ì¸ì‹)`;
      }
    }
  });

  let ocrRunning = false;
  let lastSolvedSnippet = "";
  let lastBlocked = null;
  let lastOcrTime = 0;

  // ë°ê¸° + ì›€ì§ì„ ê°ì§€ìš© ì¸ë„¤ì¼ ìº”ë²„ìŠ¤
  const BW = 64, BH = 36;
  const bCanvas = document.createElement('canvas');
  const bCtx = bCanvas.getContext('2d');
  bCanvas.width = BW;
  bCanvas.height = BH;
  let prevThumb = null;
  let lastStableTime = 0;

  // ê³ í•´ìƒë„ ìŠ¤í‹¸ í”„ë ˆì„ìš© ImageCapture
  let imageCapture = null;

  zoomRange.addEventListener("input", () => {
    const scale = parseFloat(zoomRange.value);
    video.style.transform = `scale(${scale})`;
  });

  btnOCRNow.addEventListener("click", () => {
    if (ocrRunning) return;
    lastOcrTime = Date.now();
    doOCROnce(true);
  });

  // ---------- ì¹´ë©”ë¼ ì‹œì‘ ----------
  async function startCamera() {
    try {
      const constraints = {
        video: {
          facingMode: { ideal: "environment" },
          width: { ideal: 1920 },
          height: { ideal: 1080 },
          aspectRatio: { ideal: 16 / 9 },
          frameRate: { ideal: 30 },
          advanced: [
            { width: 2560, height: 1440 },
            { width: 1920, height: 1080 }
          ]
        },
        audio: false
      };

      const stream = await navigator.mediaDevices.getUserMedia(constraints);
      video.srcObject = stream;

      const track = stream.getVideoTracks()[0];
      if (track) {
        if ("contentHint" in track) {
          try {
            track.contentHint = "detail";
          } catch (e) {
            console.warn("contentHint ì„¤ì • ì‹¤íŒ¨:", e);
          }
        }

        const s = track.getSettings ? track.getSettings() : {};
        const resInfo =
          s.width && s.height ? ` (${s.width}x${s.height}) ` : " ";

        statusLine.textContent =
          `ì¹´ë©”ë¼ ON${resInfo}â€“ ëª¨ë“œ: ${currentMode} (í™”ë©´ ì•ˆì •ë˜ë©´ ìë™ ì¸ì‹)`;

        if ("ImageCapture" in window) {
          try {
            imageCapture = new ImageCapture(track);
          } catch (e) {
            console.warn("ImageCapture ìƒì„± ì‹¤íŒ¨, video í”„ë ˆì„ fallback:", e);
            imageCapture = null;
          }
        }
      }

      startAutoLoop();
    } catch (e) {
      console.error(e);
      statusLine.textContent = "ì¹´ë©”ë¼ ì ‘ê·¼ ì‹¤íŒ¨: " + e.toString();
    }
  }

  // ---------- ë°ê¸° + ì›€ì§ì„ ë¶„ì„ ----------
  function analyzeFrame() {
    if (!video.videoWidth || !video.videoHeight) {
      return { blocked: false, stable: false };
    }

    bCtx.drawImage(video, 0, 0, BW, BH);
    const data = bCtx.getImageData(0, 0, BW, BH).data;
    const len = BW * BH;

    let sumBright = 0;
    let diffSum = 0;
    const currThumb = new Uint8Array(len);

    for (let i = 0, p = 0; i < data.length; i += 4, p++) {
      const r = data[i];
      const g = data[i + 1];
      const b = data[i + 2];
      const gray = (r + g + b) / 3;
      currThumb[p] = gray;
      sumBright += gray;
      if (prevThumb) {
        diffSum += Math.abs(gray - prevThumb[p]);
      }
    }

    const avgBright = sumBright / len;
    const diffAvg   = prevThumb ? (diffSum / len) : 0;

    const blocked = avgBright < 20;

    const now = Date.now();
    let stable = false;
    if (diffAvg < 8) {
      if (!lastStableTime) {
        lastStableTime = now;
      } else if (now - lastStableTime > 1000) {
        stable = true;
      }
    } else {
      lastStableTime = 0;
    }

    prevThumb = currThumb;

    return { blocked, stable };
  }

  // ---------- ìë™ ë£¨í”„ ----------
  function startAutoLoop() {
    function loop() {
      const now = Date.now();

      const { blocked, stable } = analyzeFrame();

      if (blocked !== lastBlocked) {
        lastBlocked = blocked;
        db.ref("p2p/state").update({
          cameraBlocked: blocked,
          cameraUpdatedAt: Date.now()
        });
        const base = statusLine.textContent.replace(/ Â· ì¹´ë©”ë¼ ìƒíƒœ:.+$/, "");
        statusLine.textContent = blocked
          ? `${base} Â· ì¹´ë©”ë¼ ìƒíƒœ: ê°€ë ¤ì§`
          : `${base} Â· ì¹´ë©”ë¼ ìƒíƒœ: ì •ìƒ`;
      }

      if (!blocked && stable && !ocrRunning && now - lastOcrTime > 8000) {
        lastOcrTime = now;
        doOCROnce(false);
      }

      requestAnimationFrame(loop);
    }
    requestAnimationFrame(loop);
  }

  // ---------- ìŠ¤í‹¸ ìº¡ì²˜ ----------
  async function captureToCanvas(canvas, ctx) {
    if (imageCapture && typeof imageCapture.takePhoto === "function") {
      try {
        const blob = await imageCapture.takePhoto();
        const imgBitmap = await createImageBitmap(blob);
        drawCroppedScaled(imgBitmap, canvas, ctx);
        return;
      } catch (e) {
        console.warn("takePhoto ì‹¤íŒ¨, grabFrame ì‹œë„:", e);
      }
    }

    if (imageCapture && typeof imageCapture.grabFrame === "function") {
      try {
        const bitmap = await imageCapture.grabFrame();
        drawCroppedScaled(bitmap, canvas, ctx);
        return;
      } catch (e) {
        console.warn("grabFrame ì‹¤íŒ¨, video í”„ë ˆì„ fallback:", e);
      }
    }

    fillCanvasFromVideoCenter(canvas, ctx);
  }

  function drawCroppedScaled(source, canvas, ctx) {
    const fullW = source.width;
    const fullH = source.height;

    const scaleCrop = 0.9;
    const cropW = Math.floor(fullW * scaleCrop);
    const cropH = Math.floor(fullH * scaleCrop);
    const cropX = Math.floor((fullW - cropW) / 2);
    const cropY = Math.floor((fullH - cropH) / 2);

    const maxW = 1600;
    const scale = Math.min(1, maxW / cropW);
    const outW = Math.floor(cropW * scale);
    const outH = Math.floor(cropH * scale);

    canvas.width = outW;
    canvas.height = outH;
    ctx.drawImage(
      source,
      cropX, cropY, cropW, cropH,
      0, 0, outW, outH
    );
  }

  function fillCanvasFromVideoCenter(canvas, ctx) {
    if (!video.videoWidth || !video.videoHeight) {
      canvas.width = 640;
      canvas.height = 360;
      ctx.fillStyle = "black";
      ctx.fillRect(0, 0, canvas.width, canvas.height);
      return;
    }
    const fullW = video.videoWidth;
    const fullH = video.videoHeight;

    const scaleCrop = 0.9;
    const cropW = Math.floor(fullW * scaleCrop);
    const cropH = Math.floor(fullH * scaleCrop);
    const cropX = Math.floor((fullW - cropW) / 2);
    const cropY = Math.floor((fullH - cropH) / 2);

    const maxW = 1600;
    const scale = Math.min(1, maxW / cropW);
    const outW = Math.floor(cropW * scale);
    const outH = Math.floor(cropH * scale);

    canvas.width = outW;
    canvas.height = outH;
    ctx.drawImage(
      video,
      cropX, cropY, cropW, cropH,
      0, 0, outW, outH
    );
  }

  // ---------- OCR 1íšŒ ----------
  async function doOCROnce(manual) {
    if (ocrRunning) return;
    ocrRunning = true;

    try {
      statusLine.textContent = manual
        ? "ìˆ˜ë™ OCR ì§„í–‰ ì¤‘..."
        : "ìë™ OCR ì§„í–‰ ì¤‘...";

      const canvas = document.createElement('canvas');
      const ctx = canvas.getContext('2d');

      await captureToCanvas(canvas, ctx);

      const result = await Tesseract.recognize(canvas, OCR_LANG, {
        logger: m => {
          if (m.status === "recognizing text") {
            statusLine.textContent =
              (manual ? "[ìˆ˜ë™] " : "[ìë™] ") +
              `OCR ì§„í–‰ ì¤‘... ${Math.round((m.progress || 0) * 100)}%`;
          }
        }
      });

      const rawText = result.data.text || "";
      const text = rawText.replace(/\s+\n/g, "\n").trim();
      const conf = result.data.confidence || 0;

      const effectiveLen = text.replace(/\s/g, "").length;
      if (!text || effectiveLen < 8) {
        statusLine.textContent =
          `OCR ì™„ë£Œ (í…ìŠ¤íŠ¸ ë„ˆë¬´ ì§§ì•„ì„œ ë¬´ì‹œ: ê¸¸ì´=${effectiveLen}, conf=${conf.toFixed(1)}%)`;
        ocrRunning = false;
        return;
      }

      if (conf < 5) {
        statusLine.textContent =
          `OCR ì™„ë£Œ (ì‹ ë¢°ë„ ${conf.toFixed(1)}%ë¡œ ë„ˆë¬´ ë‚®ì•„ì„œ ë¬´ì‹œí•¨)`;
        ocrRunning = false;
        return;
      }

      statusLine.textContent =
        `OCR ì™„ë£Œ | ê¸¸ì´=${effectiveLen}, conf=${conf.toFixed(1)}% | ëª¨ë“œ=${currentMode}`;

      await db.ref("p2p/state").update({
        ocrText: text,
        ocrConfidence: conf,
        cameraBlocked: false,
        ocrUpdatedAt: Date.now()
      });

      const snippet = text.slice(0, 400);
      if (snippet !== lastSolvedSnippet) {
        lastSolvedSnippet = snippet;
        await db.ref("p2p/command").set({
          type: "solve",
          timestamp: Date.now()
        });
      }
    } catch (e) {
      console.error(e);
      statusLine.textContent = "OCR ì—ëŸ¬: " + e.toString();
    } finally {
      ocrRunning = false;
    }
  }

  startCamera();
</script>

<!-- ğŸ”¹ solve í•¨ìˆ˜ ì§ì ‘ í˜¸ì¶œ JS (ì ˆëŒ€ URL + JSON/HTML ì•ˆì „ ì²˜ë¦¬) -->
<script>
  const SOLVE_URL = "https://beamish-alpaca-e3df59.netlify.app/.netlify/functions/solve";

  async function callSolve() {
    const inputEl = document.getElementById("ocrTextInput");
    const outputEl = document.getElementById("answerOutput");

    const ocrText = (inputEl.value || "").trim();
    if (!ocrText) {
      alert("OCRë¡œ ì¸ì‹ëœ ì œì‹œë¬¸ + [ë¬¸ì œ 1], [ë¬¸ì œ 2] í…ìŠ¤íŠ¸ë¥¼ ë¨¼ì € ì…ë ¥í•´ ì¤˜.");
      return;
    }

    outputEl.textContent = "í’€ì´ ìƒì„± ì¤‘...";

    try {
      const res = await fetch(SOLVE_URL, {
        method: "POST",
        headers: {
          "Content-Type": "application/json"
        },
        body: JSON.stringify({ ocrText })
      });

      const contentType = res.headers.get("content-type") || "";

      if (contentType.includes("application/json")) {
        let data;
        try {
          data = await res.json();
        } catch (e) {
          outputEl.textContent = "JSON íŒŒì‹± ì—ëŸ¬: " + (e.message || String(e));
          return;
        }

        if (res.ok && data.answer) {
          outputEl.textContent = data.answer;
        } else {
          outputEl.textContent =
            "ì—ëŸ¬ ë°œìƒ\n" +
            "status: " + res.status + "\n" +
            "message: " + (data.error || JSON.stringify(data));
        }
        return;
      }

      const text = await res.text();
      outputEl.textContent =
        "ì„œë²„ê°€ JSONì´ ì•„ë‹ˆë¼ HTML/textë¥¼ ëŒë ¤ì¤Œ.\n\n" +
        text.slice(0, 1000);
    } catch (err) {
      outputEl.textContent = "ìš”ì²­ ì‹¤íŒ¨: " + (err.message || String(err));
    }
  }

  document.getElementById("solveButton")
    .addEventListener("click", callSolve);
</script>
</body>
</html>

