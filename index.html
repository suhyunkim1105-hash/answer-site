<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8">
  <title>ìë™ OCR â†’ ìë™ í’€ì´ â†’ ì •ë‹µ TTS</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=cover">
  <style>
    body {
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", system-ui, sans-serif;
      margin: 0;
      padding: 16px;
      background: #fafafa;
      box-sizing: border-box;
    }
    h1 {
      font-size: 22px;
      margin: 0 0 12px 0;
    }
    #log {
      width: 100%;
      height: 120px;
      box-sizing: border-box;
      font-family: SFMono-Regular, Menlo, Consolas, monospace;
      font-size: 12px;
      padding: 8px;
      white-space: pre-wrap;
      border-radius: 8px;
      border: 1px solid #ddd;
      background: #fff;
    }
    .btn-row {
      display: flex;
      flex-wrap: wrap;
      gap: 8px;
      margin: 12px 0;
    }
    button {
      flex: 1 1 120px;
      padding: 10px 8px;
      font-size: 15px;
      border-radius: 10px;
      border: none;
      cursor: pointer;
    }
    #btnAudio { background: #e3f2fd; }
    #btnAuto  { background: #ffe0b2; }
    #btnStop  { background: #ffcdd2; }
    #btnReplay{ background: #e0f2f1; }

    #videoWrapper {
      margin-top: 8px;
      width: 100%;
      max-height: 420px;
      display: flex;
      justify-content: center;
      align-items: center;
      background: #000;
      border-radius: 10px;
      overflow: hidden;
    }
    video {
      width: 100%;
      height: auto;
      transform: rotate(0deg);
    }

    #ocrBox {
      width: 100%;
      height: 200px;
      margin-top: 12px;
      box-sizing: border-box;
      font-size: 12px;
      font-family: SFMono-Regular, Menlo, Consolas, monospace;
      border-radius: 8px;
      border: 1px solid #ddd;
      padding: 8px;
    }

    small {
      font-size: 11px;
      color: #555;
      display: block;
      margin-top: 4px;
      line-height: 1.4;
    }
  </style>
</head>
<body>
  <h1>ìë™ OCR â†’ ìë™ í’€ì´ â†’ ì •ë‹µ TTS</h1>

  <textarea id="log" readonly></textarea>

  <div class="btn-row">
    <button id="btnAudio">ğŸ”Š ì˜¤ë””ì˜¤ ì¤€ë¹„(í•œ ë²ˆë§Œ)</button>
    <button id="btnAuto">ğŸ“¸ ìë™ ì‹œì‘</button>
  </div>
  <div class="btn-row">
    <button id="btnStop">â›” ì¤‘ì§€</button>
    <button id="btnReplay">ğŸ” ì •ë‹µ ë‹¤ì‹œ ë“£ê¸°</button>
  </div>

  <small>
    - ë§ˆì§€ë§‰ í˜ì´ì§€ ì–´ë”˜ê°€ì— <b>XVRTH</b> ë˜ëŠ” <b>XURTH</b>ë¥¼ êµµê³  í¬ê²Œ ì“°ë©´, ê·¸ í˜ì´ì§€ OCR í›„ ìë™ìœ¼ë¡œ í’€ê¸°ë¡œ ë„˜ì–´ê°„ë‹¤.<br>
    - iOS ì‚¬ì¼ëŸ°íŠ¸(ë¬´ìŒ) ëª¨ë“œë©´ TTSê°€ ì•ˆ ë“¤ë¦´ ìˆ˜ ìˆë‹¤. ë¬´ìŒ í•´ì œ + ë³¼ë¥¨ ì˜¬ë ¤ë¼.<br>
    - ì¢…ì´ëŠ” í™”ë©´ì—ì„œ í¬ê²Œ(ê±°ì˜ ê½‰ ì°¨ê²Œ) ì¡ê³ , ê¸€ìê°€ ë˜ë ·í•˜ê²Œ ë‚˜ì˜¤ë„ë¡ ì •ë©´ì—ì„œ ì°ì–´ë¼.
  </small>

  <div id="videoWrapper">
    <video id="video" autoplay playsinline muted></video>
  </div>
  <canvas id="canvas" style="display:none;"></canvas>

  <h3>OCR ëˆ„ì  í…ìŠ¤íŠ¸(ë””ë²„ê·¸)</h3>
  <textarea id="ocrBox" readonly></textarea>

  <script>
    // ---------- ê³µí†µ ìƒíƒœ ----------
    const logBox   = document.getElementById("log");
    const video    = document.getElementById("video");
    const canvas   = document.getElementById("canvas");
    const ocrBox   = document.getElementById("ocrBox");
    const btnAudio = document.getElementById("btnAudio");
    const btnAuto  = document.getElementById("btnAuto");
    const btnStop  = document.getElementById("btnStop");
    const btnReplay= document.getElementById("btnReplay");

    let mediaStream = null;
    let autoRunning = false;
    let audioReady  = false;
    let ttsVoice    = null;
    let ocrAllText  = "";
    let answersMap  = null;

    const STOP_TOKEN_1 = "XVRTH";
    const STOP_TOKEN_2 = "XURTH";

    const SHOTS_PER_PAGE = 3;
    const MAX_PAGES = 10;

    function nowTime() {
      const d = new Date();
      const hh = String(d.getHours()).padStart(2, "0");
      const mm = String(d.getMinutes()).padStart(2, "0");
      const ss = String(d.getSeconds()).padStart(2, "0");
      return `${hh}ì‹œ ${mm}ë¶„ ${ss}ì´ˆ`;
    }

    function log(msg) {
      console.log(msg);
      logBox.value = `[${nowTime()}] ${msg}\n` + logBox.value;
    }

    function delay(ms) {
      return new Promise(resolve => setTimeout(resolve, ms));
    }

    // ---------- TTS ----------
    function pickKoreanVoice() {
      const voices = window.speechSynthesis.getVoices() || [];
      // ìœ ë‚˜ê°€ ìˆìœ¼ë©´ ìµœìš°ì„ 
      const yuna = voices.find(v =>
        /ìœ ë‚˜/i.test(v.name || "") || /Yuna/i.test(v.name || "")
      );
      if (yuna) return yuna;
      // ko-KR ì•„ë¬´ê±°ë‚˜
      const ko = voices.find(v => v.lang && v.lang.toLowerCase().startsWith("ko"));
      if (ko) return ko;
      // ê·¸ë˜ë„ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸
      return voices[0] || null;
    }

    function ensureTtsVoice() {
      return new Promise(resolve => {
        let v = pickKoreanVoice();
        if (v) {
          ttsVoice = v;
          log(`TTS voice: ${v.name} (${v.lang})`);
          resolve(v);
          return;
        }
        // ì•„ì§ ë¡œë”© ì•ˆ ëœ ê²½ìš°
        window.speechSynthesis.onvoiceschanged = () => {
          v = pickKoreanVoice();
          if (v) {
            ttsVoice = v;
            log(`TTS voice: ${v.name} (${v.lang})`);
            resolve(v);
          }
        };
      });
    }

    function speakOnce(text) {
      return new Promise(async resolve => {
        if (!ttsVoice) {
          await ensureTtsVoice();
        }
        const u = new SpeechSynthesisUtterance(text);
        u.lang = "ko-KR";
        u.rate = 0.9;
        u.voice = ttsVoice || null;
        u.onend = () => resolve();
        try {
          window.speechSynthesis.speak(u);
        } catch (e) {
          console.warn("speech error", e);
          resolve();
        }
      });
    }

    async function prepareAudio() {
      try {
        const AC = window.AudioContext || window.webkitAudioContext;
        if (AC) {
          const ctx = new AC();
          if (ctx.state === "suspended" && ctx.resume) {
            await ctx.resume();
          }
          log("AudioContext ì–¸ë½ ì™„ë£Œ ëŒ€ê¸° ì¤‘");
        }
      } catch (e) {
        console.warn("AudioContext error", e);
      }
      await ensureTtsVoice();
      await speakOnce("ì˜¤ë””ì˜¤ ì¤€ë¹„ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.");
      audioReady = true;
      log("ì˜¤ë””ì˜¤ ì¤€ë¹„ ì™„ë£Œ(ë²„íŠ¼)");
    }

    async function readAnswersRepeated() {
      if (!answersMap || !Object.keys(answersMap).length) {
        log("ì •ë‹µ ë°ì´í„°ê°€ ì—†ì–´ ë‹¤ì‹œ ë“£ê¸°ë¥¼ í•  ìˆ˜ ì—†ìŒ");
        await speakOnce("ì•„ì§ ì •ë‹µì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì‹œí—˜ì§€ë¥¼ ì´¬ì˜í•´ì„œ í’€ì–´ì•¼ í•©ë‹ˆë‹¤.");
        return;
      }
      const letters = ["A", "B", "C", "D", "E"];
      const keys = Object.keys(answersMap).map(n => parseInt(n, 10)).sort((a,b) => a - b);

      for (let round = 1; round <= 4; round++) {
        log(`ì •ë‹µ ì½ê¸° ì‹œì‘(${round}/4)`);
        await speakOnce(`ì •ë‹µì„ ${round}ë²ˆì§¸ë¡œ ì½ê² ìŠµë‹ˆë‹¤.`);
        for (const q of keys) {
          const idx = answersMap[q];
          const ch = letters[idx - 1] || String(idx);
          await speakOnce(`${q}ë²ˆ ${ch}`);
          await delay(2000); // ë‹µ ì‚¬ì´ 2ì´ˆ
        }
        await delay(3000); // ë¼ìš´ë“œ ì‚¬ì´ 3ì´ˆ
      }
    }

    // ---------- ì¹´ë©”ë¼ ----------
    async function startCamera() {
      if (mediaStream) return;
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        log("getUserMedia ì§€ì› ì•ˆ ë¨");
        await speakOnce("ì´ ë¸Œë¼ìš°ì €ì—ì„œëŠ” ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.");
        return;
      }
      try {
        mediaStream = await navigator.mediaDevices.getUserMedia({
          video: {
            facingMode: "environment"
          },
          audio: false
        });
        video.srcObject = mediaStream;
        await video.play();
        log(`ì¹´ë©”ë¼ OK (${video.videoWidth}x${video.videoHeight})`);
      } catch (e) {
        log("ì¹´ë©”ë¼ ì˜¤ë¥˜: " + e.message);
        await speakOnce("ì¹´ë©”ë¼ ê¶Œí•œì„ í—ˆìš©í•´ ì£¼ì„¸ìš”.");
      }
    }

    function stopCamera() {
      if (mediaStream) {
        mediaStream.getTracks().forEach(t => t.stop());
        mediaStream = null;
      }
      video.srcObject = null;
    }

    function captureFrameToDataUrl() {
      const vw = video.videoWidth || 1080;
      const vh = video.videoHeight || 1920;
      canvas.width = vw;
      canvas.height = vh;
      const ctx = canvas.getContext("2d");
      ctx.drawImage(video, 0, 0, vw, vh);
      // JPEG í’ˆì§ˆ 0.8
      return canvas.toDataURL("image/jpeg", 0.8);
    }

    // ---------- OCR ----------
    async function callOcr(imageDataUrl) {
      try {
        const resp = await fetch("/.netlify/functions/ocr", {
          method: "POST",
          headers: {
            "content-type": "application/json"
          },
          body: JSON.stringify({ image: imageDataUrl })
        });
        const data = await resp.json();
        return data;
      } catch (e) {
        return { ok: false, error: "fetch error", detail: String(e.message || e) };
      }
    }

    function hasStopToken(text) {
      const up = String(text || "").toUpperCase();
      return up.includes(STOP_TOKEN_1) || up.includes(STOP_TOKEN_2);
    }

    // ---------- OCR í…ìŠ¤íŠ¸ â†’ ë¬¸í•­ íŒŒì‹± ----------
    function parseQuestionsFromOcr(allText) {
      const text = String(allText || "").replace(/\r/g, "");
      const lines = text.split("\n");

      const blocks = {};
      let currentNo = null;

      for (let raw of lines) {
        const line = raw.trim();
        if (!line) continue;
        const m = line.match(/^(\d{1,2})[). ]\s*(.*)$/); // "01 ..." / "1 ..."
        if (m) {
          const qn = parseInt(m[1], 10);
          if (qn >= 1 && qn <= 50) {
            currentNo = qn;
            if (!blocks[qn]) blocks[qn] = [];
            if (m[2]) blocks[qn].push(m[2]);
            continue;
          }
        }
        if (currentNo != null) {
          blocks[currentNo].push(line);
        }
      }

      const questions = [];
      const nums = Object.keys(blocks)
        .map(n => parseInt(n, 10))
        .sort((a,b) => a - b);

      const choiceLineRegex = /^([1-5]|[â‘ -â‘¤])[). ]\s+|^[â€¢*@Â®Â©]/;

      for (const n of nums) {
        const rawLines = blocks[n];
        if (!rawLines || !rawLines.length) continue;

        const choiceLines = [];
        const stemLines = [];

        for (const raw of rawLines) {
          const line = raw.trim();
          if (!line) continue;
          if (choiceLineRegex.test(line)) {
            const cleaned = line.replace(choiceLineRegex, "").trim();
            if (cleaned) choiceLines.push(cleaned);
          } else {
            stemLines.push(line);
          }
        }

        let choices = choiceLines.slice(0, 5);
        if (choices.length < 5) {
          // í¼ì´ ì–´ê¸‹ë‚˜ë©´ ë§ˆì§€ë§‰ 5ì¤„ì„ ì„ íƒí•˜ëŠ” fallback
          const nonEmpty = rawLines.map(x => x.trim()).filter(Boolean);
          choices = nonEmpty.slice(-5);
          stemLines.length = Math.max(0, nonEmpty.length - 5);
        }

        const stem = stemLines.join(" ");
        if (!stem || stem.length < 8) continue;
        if (!choices || choices.length < 5) continue;

        questions.push({
          number: n,
          stem: stem,
          choices: choices.slice(0, 5)
        });
      }

      return questions;
    }

    async function callSolveWithText(allText) {
      const questions = parseQuestionsFromOcr(allText);
      if (!questions.length) {
        log("ë¬¸í•­ íŒŒì‹± ì‹¤íŒ¨: questions ì—†ìŒ");
        await speakOnce("ë¬¸í•­ì„ ì œëŒ€ë¡œ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì´¬ì˜í•´ ì£¼ì„¸ìš”.");
        return;
      }
      log(`ë¬¸í•­ íŒŒì‹± OK: ${questions.length}ê°œ`);

      try {
        const resp = await fetch("/.netlify/functions/solve", {
          method: "POST",
          headers: { "content-type": "application/json" },
          body: JSON.stringify({ questions: questions })
        });
        const data = await resp.json();
        if (!data.ok) {
          log("ì •ë‹µ ê³„ì‚° ì‹¤íŒ¨: " + (data.error || "unknown"));
          await speakOnce("ì •ë‹µ ê³„ì‚°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.");
          return;
        }
        answersMap = data.answers || {};
        log("ì •ë‹µ ìˆ˜ì‹  OK: " + JSON.stringify(answersMap));
        await readAnswersRepeated();
      } catch (e) {
        log("solve fetch error: " + e.message);
        await speakOnce("ì •ë‹µ ì„œë²„ í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.");
      }
    }

    // ---------- ìë™ ë£¨í”„ ----------
    async function runAuto() {
      if (autoRunning) return;
      autoRunning = true;
      ocrAllText = "";
      answersMap = null;
      ocrBox.value = "";

      await startCamera();

      if (!audioReady) {
        await prepareAudio();
      }

      await speakOnce("ìë™ ì˜¤ì”¨ì•Œì„ ì‹œì‘í•©ë‹ˆë‹¤. ì²« ë²ˆì§¸ í˜ì´ì§€ë¥¼ í™”ë©´ì— ê½‰ ì°¨ê²Œ ë³´ì—¬ ì£¼ì„¸ìš”.");

      let stopFound = false;
      let page = 1;

      while (autoRunning && page <= MAX_PAGES && !stopFound) {
        log(`í˜ì´ì§€ ${page} OCR ì‹œì‘`);

        let bestText = "";
        let bestConf = 0;

        for (let shot = 1; shot <= SHOTS_PER_PAGE && autoRunning; shot++) {
          log(`í˜ì´ì§€ ${page} / ìƒ· ${shot} ì´¬ì˜`);
          const dataUrl = captureFrameToDataUrl();
          const ocrRes = await callOcr(dataUrl);

          if (!autoRunning) break;

          if (!ocrRes || !ocrRes.ok) {
            log(`OCR FAIL page=${page} shot=${shot}: ${ocrRes && ocrRes.error}`);
            continue;
          }

          const text = String(ocrRes.text || "");
          const conf = Number(ocrRes.conf || 0);
          log(`OCR OK page=${page} shot=${shot} len=${text.length} conf=${conf}`);

          if (text.length > bestText.length) {
            bestText = text;
            bestConf = conf;
          }

          if (hasStopToken(text)) {
            stopFound = true;
          }

          await delay(500); // ìƒ· ì‚¬ì´ 0.5ì´ˆ
        }

        if (bestText) {
          ocrAllText += `\n[PAGE ${page}]\n` + bestText + "\n";
          ocrBox.value = ocrAllText;
        }

        if (!autoRunning) break;

        if (stopFound) {
          log("STOP TOKEN ê°ì§€ â†’ ìë™ ì´¬ì˜ ì¢…ë£Œ");
          await speakOnce("ë§ˆì§€ë§‰ í˜ì´ì§€ë¥¼ ì¸ì‹í–ˆìŠµë‹ˆë‹¤. ì´ì œ ë¬¸ì œë¥¼ í’‰ë‹ˆë‹¤.");
          break;
        } else {
          page++;
          if (page > MAX_PAGES) break;
          await speakOnce(`í˜ì´ì§€ ${page}ë¥¼ í™”ë©´ì— ë³´ì—¬ ì£¼ì„¸ìš”.`);
          await delay(3000);
        }
      }

      autoRunning = false;
      stopCamera();

      if (ocrAllText.trim().length < 50) {
        log("ì „ì²´ OCR í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŒ â†’ í’€ì´ ìŠ¤í‚µ");
        await speakOnce("ìœ íš¨í•œ í…ìŠ¤íŠ¸ë¥¼ ì¶©ë¶„íˆ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì´¬ì˜í•´ ì£¼ì„¸ìš”.");
        return;
      }

      await callSolveWithText(ocrAllText);
    }

    function stopAll() {
      autoRunning = false;
      stopCamera();
      window.speechSynthesis.cancel();
      log("STOP");
    }

    // ---------- ë²„íŠ¼ ì´ë²¤íŠ¸ ----------
    btnAudio.addEventListener("click", () => {
      prepareAudio();
    });

    btnAuto.addEventListener("click", () => {
      runAuto();
    });

    btnStop.addEventListener("click", () => {
      stopAll();
    });

    btnReplay.addEventListener("click", () => {
      readAnswersRepeated();
    });

    // iOSì—ì„œ ì²« ë¡œë”© í›„ ìŒì„± ì—”ì§„ ì¤€ë¹„ìš© (ë¬´ìŒ ëª¨ë“œ/ê¶Œí•œ ë¬¸ì œëŠ” ì‚¬ìš©ìê°€ ì„¤ì •)
    log("ëŒ€ê¸° ì¤‘");
  </script>
</body>
</html>
