<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8" />
  <title>autononsul | Phone OCR</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

  <!-- Firebase (결과 저장/수신용) -->
  <script src="https://www.gstatic.com/firebasejs/11.1.0/firebase-app-compat.js"></script>
  <script src="https://www.gstatic.com/firebasejs/11.1.0/firebase-database-compat.js"></script>

  <style>
    * { box-sizing: border-box; }
    body { margin:0; padding:10px; background:#000; color:#fff; font-family:system-ui,-apple-system,BlinkMacSystemFont,sans-serif; }
    h3 { margin:8px 0; }
    #topStatus { font-size:13px; color:#c4f1ff; white-space:pre-wrap; }
    #videoBox { position:relative; width:100%; border:1px solid #333; border-radius:10px; overflow:hidden; background:#000; }
    #video { width:100%; height:auto; transform:scale(0.8); transform-origin:center center; } /* 표시용 0.8배율 */
    #frame { position:absolute; inset:0; border:2px solid rgba(0,255,0,0.35); pointer-events:none; border-radius:10px; }
    .row { display:flex; gap:8px; margin-top:10px; }
    button { padding:10px 12px; font-size:14px; border-radius:10px; border:1px solid #666; background:#111; color:#fff; }
    button:active { transform: scale(0.98); }

    textarea, pre {
      width:100%;
      background:#050505; color:#fff;
      border:1px solid #333; border-radius:10px;
      padding:10px; font-size:12px; font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, monospace;
      white-space:pre-wrap;
    }
    pre { min-height:140px; }
    .small { font-size:12px; color:#bbb; }
  </style>
</head>

<body>
  <div id="topStatus">준비 중...</div>

  <div id="videoBox" style="margin-top:10px;">
    <video id="video" autoplay playsinline muted></video>
    <div id="frame"></div>
  </div>

  <div class="row">
    <button id="btnStart">자동 OCR 시작</button>
    <button id="btnStop">자동 OCR 정지</button>
    <button id="btnSpeakTest">음성 테스트</button>
  </div>

  <h3 style="margin-top:14px;">실시간 OCR(누적)</h3>
  <div class="small">OCR은 서버에서 처리됨(폰은 사진만 보냄). 네트워크가 느리면 5초 주기가 밀릴 수 있음.</div>
  <textarea id="ocrBox" rows="10" placeholder="여기에 누적 텍스트가 쌓임"></textarea>

  <h3>답안</h3>
  <pre id="answerBox"></pre>

<script>
  // ---------- Firebase ----------
  const firebaseConfig = {
    apiKey: "AIzaSyAvjpHfmbuHQq3ZeV6mNKQFI9LsnX-vf68",
    authDomain: "answer-site-p2p.firebaseapp.com",
    databaseURL: "https://answer-site-p2p-default-rtdb.asia-southeast1.firebasedatabase.app",
    projectId: "answer-site-p2p",
    storageBucket: "answer-site-p2p.firebasestorage.app",
    messagingSenderId: "364227113735",
    appId: "1:364227113735:web:b18355cf0b16454663cba2",
    measurementId: "G-C8MRHK5ZGS"
  };
  firebase.initializeApp(firebaseConfig);
  const db = firebase.database();

  // ---------- UI ----------
  const topStatus = document.getElementById("topStatus");
  const video = document.getElementById("video");
  const ocrBox = document.getElementById("ocrBox");
  const answerBox = document.getElementById("answerBox");
  const btnStart = document.getElementById("btnStart");
  const btnStop = document.getElementById("btnStop");
  const btnSpeakTest = document.getElementById("btnSpeakTest");

  // ---------- Settings ----------
  const OCR_URL = "/.netlify/functions/ocr";
  const SOLVE_BG_URL = "/.netlify/functions/solve-background";
  const OCR_INTERVAL_MS = 5000;

  const MIN_LEN = 2400;              // 공백제외 누적 길이 기준
  const MIN_CONF = 55;               // 평균 신뢰도 기준(대충)
  const LACK_TRIGGER_SEC = 8 * 60;   // 지문 부족 8분이면 강제 풀이
  const LACK_START_SEC = 60;         // 지문 부족 판단 시작(1분)

  // ---------- State ----------
  let stream = null;
  let ocrTimer = null;
  let ocrBusy = false;

  let lines = [];            // 누적 라인 배열
  let seen = new Set();      // 중복 방지(간단 키)
  let avgConf = 0;
  let confCount = 0;

  let lastGoodAt = Date.now(); // 최근에 “의미있는 OCR”이 들어온 시간
  let autoSolveStarted = false;
  let currentJobId = null;

  // ---------- TTS ----------
  function speak(text) {
    try {
      if (!text) return;
      window.speechSynthesis.cancel();
      const u = new SpeechSynthesisUtterance(text);
      u.lang = "ko-KR";
      u.rate = 1.0;
      u.pitch = 1.0;
      window.speechSynthesis.speak(u);
    } catch (e) {}
  }

  btnSpeakTest.addEventListener("click", () => {
    speak("음성 테스트입니다.");
  });

  // ---------- Camera ----------
  async function startCamera() {
    const constraints = {
      video: {
        facingMode: { ideal: "environment" },
        width: { ideal: 1920 },
        height: { ideal: 1080 }
      },
      audio: false
    };
    stream = await navigator.mediaDevices.getUserMedia(constraints);
    video.srcObject = stream;
  }

  function stopCamera() {
    try {
      if (!stream) return;
      stream.getTracks().forEach(t => t.stop());
      stream = null;
    } catch (e) {}
  }

  // ---------- Capture frame -> JPEG base64 ----------
  async function captureJpegBase64() {
    const w = video.videoWidth || 1280;
    const h = video.videoHeight || 720;

    // 중앙 크롭(90%) + 축소(최대 1600폭)
    const cropScale = 0.90;
    const cw = Math.floor(w * cropScale);
    const ch = Math.floor(h * cropScale);
    const cx = Math.floor((w - cw) / 2);
    const cy = Math.floor((h - ch) / 2);

    const maxW = 1600;
    const outScale = Math.min(1, maxW / cw);
    const ow = Math.floor(cw * outScale);
    const oh = Math.floor(ch * outScale);

    const canvas = document.createElement("canvas");
    canvas.width = ow;
    canvas.height = oh;
    const ctx = canvas.getContext("2d");

    // 약간 선명하게(지원되는 브라우저만)
    try {
      ctx.filter = "contrast(1.25) brightness(1.05)";
    } catch(e) {}

    ctx.drawImage(video, cx, cy, cw, ch, 0, 0, ow, oh);

    const blob = await new Promise(res => canvas.toBlob(res, "image/jpeg", 0.72));
    const arrBuf = await blob.arrayBuffer();
    const bytes = new Uint8Array(arrBuf);

    // base64
    let bin = "";
    for (let i = 0; i < bytes.length; i++) bin += String.fromCharCode(bytes[i]);
    return btoa(bin);
  }

  // ---------- Merge OCR text (간단 누적/교정 느낌) ----------
  function normalizeLine(s) {
    return (s || "")
      .replace(/\u00A0/g, " ")
      .replace(/[ \t]+/g, " ")
      .trim();
  }

  function addLinesFromText(text) {
    const raw = (text || "").split(/\r?\n/).map(normalizeLine).filter(Boolean);

    let added = 0;
    for (const ln of raw) {
      // 너무 짧은 찌꺼기 제거
      const coreLen = ln.replace(/\s/g, "").length;
      if (coreLen < 6) continue;

      // 중복키(앞 22자)
      const key = ln.replace(/\s/g,"").slice(0, 22);
      if (seen.has(key)) continue;

      seen.add(key);
      lines.push(ln);
      added++;
    }

    if (added > 0) {
      lastGoodAt = Date.now();
      ocrBox.value = lines.join("\n");
    }
  }

  function effectiveLen() {
    return (ocrBox.value || "").replace(/\s/g, "").length;
  }

  function lackSeconds() {
    return Math.floor((Date.now() - lastGoodAt) / 1000);
  }

  // ---------- Auto solve (background) ----------
  function makeJobId() {
    return String(Date.now()) + "-" + Math.random().toString(16).slice(2);
  }

  async function startSolve(reasonLabel) {
    if (autoSolveStarted) return;
    autoSolveStarted = true;

    const text = (ocrBox.value || "").trim();
    answerBox.textContent = reasonLabel + "\n\n답안 생성 중...";

    // job 생성 + Firebase 리스너
    currentJobId = makeJobId();
    const jobRef = db.ref("p2p/jobs/" + currentJobId);

    jobRef.on("value", snap => {
      const v = snap.val();
      if (!v) return;
      if (v.status === "done" && v.answer) {
        answerBox.textContent = v.answer;
        speak(v.answer);
        jobRef.off();
      } else if (v.status === "error") {
        answerBox.textContent = (v.message || "오류") + "";
        jobRef.off();
      }
    });

    // 백그라운드 함수 호출(바로 202 리턴됨)
    try {
      await fetch(SOLVE_BG_URL, {
        method: "POST",
        headers: { "Content-Type":"application/json" },
        body: JSON.stringify({
          jobId: currentJobId,
          ocrText: text
        })
      });
    } catch (e) {
      answerBox.textContent = "solve 호출 실패: " + (e.message || String(e));
    }
  }

  // ---------- OCR loop ----------
  async function runOnce() {
    if (ocrBusy) return;
    if (!video.videoWidth) return;
    ocrBusy = true;

    try {
      const b64 = await captureJpegBase64();
      const res = await fetch(OCR_URL, {
        method: "POST",
        headers: { "Content-Type":"application/json" },
        body: JSON.stringify({ imageBase64: b64 })
      });

      const ct = res.headers.get("content-type") || "";
      if (!ct.includes("application/json")) {
        const t = await res.text();
        topStatus.textContent = "OCR 응답이 JSON이 아님:\n" + t.slice(0, 300);
        return;
      }

      const data = await res.json();
      if (!res.ok) {
        topStatus.textContent = "OCR 실패: " + (data.error || res.status);
        return;
      }

      const text = (data.text || "").trim();
      const conf = typeof data.conf === "number" ? data.conf : 0;

      // 평균 신뢰도 업데이트(대충)
      confCount++;
      avgConf = avgConf + (conf - avgConf) / confCount;

      addLinesFromText(text);

      const len = effectiveLen();
      const lack = lackSeconds();

      topStatus.textContent =
        "자동 OCR(누적) → 자동 풀이\n" +
        "누적 OCR 길이(공백제외): " + len + " / 기준 " + MIN_LEN + "\n" +
        "평균 OCR 신뢰도(대략): " + avgConf.toFixed(1) + "%\n" +
        "지문 부족 지속: " + lack + "초\n" +
        "카메라: 연결됨 | 음성: 준비됨\n" +
        "마지막 메시지: " + (data.note || "OK");

      // 자동 풀이 트리거
      if (!autoSolveStarted) {
        if (len >= MIN_LEN && avgConf >= MIN_CONF) {
          startSolve("충분한 지문 인식으로 자동 풀이합니다.");
        } else if (lack >= LACK_TRIGGER_SEC) {
          startSolve("지문 부족으로 자동 풀이합니다.\n(8분 동안 충분히 누적되지 않음)");
        }
      }

      // “지문 부족”이 1분 넘으면 음성 안내(너무 자주 말하지 않게)
      if (!autoSolveStarted && lack >= LACK_START_SEC && (lack % 30 === 0)) {
        speak("지문이 부족합니다. 종이를 화면에 더 꽉 차게 보여 주세요.");
      }

    } catch (e) {
      topStatus.textContent = "OCR 에러: " + (e.message || String(e));
    } finally {
      ocrBusy = false;
    }
  }

  function startAutoOCR() {
    if (ocrTimer) return;
    autoSolveStarted = false;
    currentJobId = null;
    topStatus.textContent = "자동 OCR 시작...";
    runOnce();
    ocrTimer = setInterval(runOnce, OCR_INTERVAL_MS);
  }

  function stopAutoOCR() {
    if (ocrTimer) clearInterval(ocrTimer);
    ocrTimer = null;
    topStatus.textContent = "자동 OCR 정지됨";
  }

  btnStart.addEventListener("click", startAutoOCR);
  btnStop.addEventListener("click", stopAutoOCR);

  // iOS에서 백그라운드로 가면 멈추는 걸 방지하려고, 숨겨지면 정지
  document.addEventListener("visibilitychange", () => {
    if (document.hidden) stopAutoOCR();
  });

  // ---------- Boot ----------
  (async () => {
    try {
      await startCamera();
      topStatus.textContent =
        "준비됨\n" +
        "1) 자동 OCR 시작을 누르세요.\n" +
        "2) 처음 페이지부터 마지막 문제까지 5~10초씩 꽉 차게 보여 주세요.";
    } catch (e) {
      topStatus.textContent = "카메라 실패: " + (e.message || String(e));
    }
  })();
</script>
</body>
</html>


