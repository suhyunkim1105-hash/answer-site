<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>answer-site | Camera</title>
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

  <!-- Firebase -->
  <script src="https://www.gstatic.com/firebasejs/11.1.0/firebase-app-compat.js"></script>
  <script src="https://www.gstatic.com/firebasejs/11.1.0/firebase-database-compat.js"></script>

  <!-- Tesseract OCR -->
  <script src="https://unpkg.com/tesseract.js@4/dist/tesseract.min.js"></script>

  <style>
    * { box-sizing: border-box; }
    body {
      margin: 0;
      padding: 6px;
      background: #000;
      color: #fff;
      font-family: system-ui, -apple-system, BlinkMacSystemFont, sans-serif;
    }
    .wrap {
      width: 100%;
    }

    /* ìƒë‹¨: ì¹´ë©”ë¼ ì˜ì—­ (ê°€ë¡œ/ì„¸ë¡œ ëª¨ë‘ ëŒ€ì‘) */
    #videoContainer {
      position: relative;
      width: 100%;
      max-height: calc(100vh - 120px);
      overflow: hidden;
      background: #000;
      border-radius: 8px;
    }
    #video {
      width: 100%;
      height: auto;
      transform-origin: center center;
    }
    #overlayFrame {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      border: 2px solid rgba(0, 255, 0, 0.4);
      border-radius: 6px;
      pointer-events: none;
    }

    /* í•˜ë‹¨ ì»¨íŠ¸ë¡¤: ìƒíƒœ + ë°°ìœ¨ + ìˆ˜ë™ ì¸ì‹ */
    #controls {
      margin-top: 6px;
      font-size: 11px;
    }

    #statusLine {
      margin-bottom: 4px;
      color: #c4f1ff;
      white-space: nowrap;
      overflow: hidden;
      text-overflow: ellipsis;
    }

    .row {
      display: flex;
      align-items: center;
      gap: 6px;
    }
    .label {
      font-size: 11px;
      color: #aaa;
      white-space: nowrap;
    }
    #zoomRange {
      flex: 1 1 auto;
    }
    #btnOCRNow {
      flex: 0 0 auto;
      padding: 4px 8px;
      font-size: 11px;
      border-radius: 6px;
      border: 1px solid #666;
      background: #111;
      color: #f5f5f5;
      cursor: pointer;
    }
    #btnOCRNow:active {
      transform: scale(0.97);
    }
  </style>
</head>
<body>
<div class="wrap">
  <div id="videoContainer">
    <video id="video" autoplay playsinline></video>
    <div id="overlayFrame"></div>
  </div>

  <div id="controls">
    <div id="statusLine">ì¹´ë©”ë¼ ì¤€ë¹„ ì¤‘...</div>

    <div class="row">
      <span class="label">ë°°ìœ¨</span>
      <input id="zoomRange" type="range" min="1" max="3" step="0.05" value="1">
      <button id="btnOCRNow">ì§€ê¸ˆ ì¸ì‹</button>
    </div>
  </div>
</div>

<script>
  // ---------------- Firebase ----------------
  const firebaseConfig = {
    apiKey: "AIzaSyAvjpHfmbuHQq3ZeV6mNKQFI9LsnX-vf68",
    authDomain: "answer-site-p2p.firebaseapp.com",
    databaseURL: "https://answer-site-p2p-default-rtdb.asia-southeast1.firebasedatabase.app",
    projectId: "answer-site-p2p",
    storageBucket: "answer-site-p2p.firebasestorage.app",
    messagingSenderId: "364227113735",
    appId: "1:364227113735:web:b18355cf0b16454663cba2",
    measurementId: "G-C8MRHK5ZGS"
  };
  firebase.initializeApp(firebaseConfig);
  const db = firebase.database();

  const video      = document.getElementById('video');
  const statusLine = document.getElementById('statusLine');
  const zoomRange  = document.getElementById('zoomRange');
  const btnOCRNow  = document.getElementById('btnOCRNow');

  // ğŸ”¤ ì˜ì–´ë§Œ ì¸ì‹ (ê°€ë¡œ/ì„¸ë¡œ ìƒê´€ ì—†ì´)
  const OCR_LANG = "eng";

  // remote.htmlì—ì„œ ì„ íƒí•œ ëª¨ë“œ ì½ì–´ì„œ í‘œì‹œë§Œ í•¨ (ì—¬ê¸°ì„œëŠ” ë²„íŠ¼ ì—†ìŒ)
  let currentMode = "reading";

  // Firebaseì—ì„œ modeHint êµ¬ë…í•´ì„œ ìƒíƒœë§Œ ë³´ì—¬ì£¼ê¸°
  db.ref("p2p/state/modeHint").on("value", snap => {
    const m = snap.val();
    if (m) {
      currentMode = m;
      statusLine.textContent = `ì¹´ë©”ë¼ ON â€“ ëª¨ë“œ: ${currentMode} (í™”ë©´ ì•ˆì •ë˜ë©´ ìë™ ì¸ì‹)`;
    }
  });

  let ocrRunning = false;
  let lastSolvedSnippet = "";
  let lastBlocked = null;
  let lastOcrTime = 0;

  // ë°ê¸° + ì›€ì§ì„ ê°ì§€ìš© ì¸ë„¤ì¼ ìº”ë²„ìŠ¤
  const BW = 64, BH = 36;
  const bCanvas = document.createElement('canvas');
  const bCtx = bCanvas.getContext('2d');
  bCanvas.width = BW;
  bCanvas.height = BH;
  let prevThumb = null;
  let lastStableTime = 0;

  // ê³ í•´ìƒë„ ìŠ¤í‹¸ í”„ë ˆì„ìš© ImageCapture
  let imageCapture = null;

  // ---------- ì¹´ë©”ë¼ ----------
  async function startCamera() {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: {
          facingMode: { ideal: "environment" },
          width:  { min: 1280, ideal: 1920, max: 2560 },
          height: { min: 720,  ideal: 1080, max: 1440 }
        },
        audio: false
      });
      video.srcObject = stream;

      const track = stream.getVideoTracks()[0];
      if ('ImageCapture' in window && track) {
        try {
          imageCapture = new ImageCapture(track);
        } catch (e) {
          console.warn("ImageCapture ìƒì„± ì‹¤íŒ¨, video í”„ë ˆì„ fallback:", e);
          imageCapture = null;
        }
      }

      if (!statusLine.textContent.includes("ëª¨ë“œ:")) {
        statusLine.textContent = `ì¹´ë©”ë¼ ON â€“ ëª¨ë“œ: ${currentMode} (í™”ë©´ ì•ˆì •ë˜ë©´ ìë™ ì¸ì‹)`;
      }
      startAutoLoop();
    } catch (e) {
      console.error(e);
      statusLine.textContent = "ì¹´ë©”ë¼ ì ‘ê·¼ ì‹¤íŒ¨: " + e.toString();
    }
  }

  zoomRange.addEventListener("input", () => {
    const scale = parseFloat(zoomRange.value);
    video.style.transform = `scale(${scale})`;
  });

  btnOCRNow.addEventListener("click", () => {
    if (ocrRunning) return;
    lastOcrTime = Date.now();
    doOCROnce(true);
  });

  // ---------- ë°ê¸° + ì›€ì§ì„ ë¶„ì„ ----------
  function analyzeFrame() {
    if (!video.videoWidth || !video.videoHeight) {
      return { blocked: false, stable: false };
    }

    bCtx.drawImage(video, 0, 0, BW, BH);
    const data = bCtx.getImageData(0, 0, BW, BH).data;
    const len = BW * BH;

    let sumBright = 0;
    let diffSum = 0;
    const currThumb = new Uint8Array(len);

    for (let i = 0, p = 0; i < data.length; i += 4, p++) {
      const r = data[i];
      const g = data[i + 1];
      const b = data[i + 2];
      const gray = (r + g + b) / 3;
      currThumb[p] = gray;
      sumBright += gray;
      if (prevThumb) {
        diffSum += Math.abs(gray - prevThumb[p]);
      }
    }

    const avgBright = sumBright / len;
    const diffAvg   = prevThumb ? (diffSum / len) : 0;

    const blocked = avgBright < 25;

    const now = Date.now();
    let stable = false;
    if (diffAvg < 8) {
      if (!lastStableTime) {
        lastStableTime = now;
      } else if (now - lastStableTime > 1000) {
        stable = true;
      }
    } else {
      lastStableTime = 0;
    }

    prevThumb = currThumb;

    return { blocked, stable };
  }

  // ---------- ìë™ ë£¨í”„ ----------
  function startAutoLoop() {
    function loop() {
      const now = Date.now();

      const { blocked, stable } = analyzeFrame();

      if (blocked !== lastBlocked) {
        lastBlocked = blocked;
        db.ref("p2p/state").update({
          cameraBlocked: blocked,
          cameraUpdatedAt: Date.now()
        });
        statusLine.textContent = blocked
          ? "ì¹´ë©”ë¼ê°€ ê°€ë ¤ì§ â€“ ë§ˆì§€ë§‰ ë‹µ ìœ ì§€ ì¤‘"
          : `ì¹´ë©”ë¼ ON â€“ ëª¨ë“œ: ${currentMode} (í™”ë©´ ì•ˆì •ë˜ë©´ ìë™ ì¸ì‹)`;
      }

      if (!blocked && stable && !ocrRunning && now - lastOcrTime > 8000) {
        lastOcrTime = now;
        doOCROnce(false);
      }

      requestAnimationFrame(loop);
    }
    requestAnimationFrame(loop);
  }

  // ---------- OCR (ì¤‘ì•™ 90% ì˜ì—­, í•„í„° ëŠìŠ¨í•˜ê²Œ) ----------
  async function doOCROnce(manual) {
    if (ocrRunning) return;
    ocrRunning = true;

    try {
      statusLine.textContent = manual
        ? "ìˆ˜ë™ OCR ì§„í–‰ ì¤‘..."
        : "ìë™ OCR ì§„í–‰ ì¤‘...";

      const canvas = document.createElement('canvas');
      const ctx = canvas.getContext('2d');

      if (imageCapture) {
        try {
          const bitmap = await imageCapture.grabFrame();
          cropCenterToCanvas(bitmap.width, bitmap.height, (x, y, w, h) => {
            canvas.width = w;
            canvas.height = h;
            ctx.drawImage(bitmap, x, y, w, h, 0, 0, w, h);
          });
        } catch (e) {
          console.warn("grabFrame ì‹¤íŒ¨, video í”„ë ˆì„ fallback:", e);
          fillCanvasFromVideoCenter(canvas, ctx);
        }
      } else {
        fillCanvasFromVideoCenter(canvas, ctx);
      }

      const result = await Tesseract.recognize(canvas, OCR_LANG, {
        logger: m => {
          if (m.status === "recognizing text") {
            statusLine.textContent =
              (manual ? "[ìˆ˜ë™] " : "[ìë™] ") +
              `OCR ì§„í–‰ ì¤‘... ${Math.round((m.progress || 0) * 100)}%`;
          }
        }
      });

      const rawText = result.data.text || "";
      const text = rawText.replace(/\s+\n/g, "\n").trim();
      const conf = result.data.confidence || 0;

      const effectiveLen = text.replace(/\s/g, "").length;
      if (!text || effectiveLen < 10) {
        statusLine.textContent =
          `OCR ì™„ë£Œ (í…ìŠ¤íŠ¸ ë„ˆë¬´ ì§§ì•„ì„œ ë¬´ì‹œ: ê¸¸ì´=${effectiveLen}, conf=${conf.toFixed(1)}%)`;
        ocrRunning = false;
        return;
      }

      statusLine.textContent =
        `OCR ì™„ë£Œ | ê¸¸ì´=${effectiveLen}, conf=${conf.toFixed(1)}% | ëª¨ë“œ=${currentMode}`;

      await db.ref("p2p/state").update({
        ocrText: text,
        ocrConfidence: conf,
        cameraBlocked: false,
        ocrUpdatedAt: Date.now()
      });

      const snippet = text.slice(0, 400);
      if (snippet !== lastSolvedSnippet) {
        lastSolvedSnippet = snippet;
        await db.ref("p2p/command").set({
          type: "solve",
          timestamp: Date.now()
        });
      }
    } catch (e) {
      console.error(e);
      statusLine.textContent = "OCR ì—ëŸ¬: " + e.toString();
    } finally {
      ocrRunning = false;
    }
  }

  // ì¤‘ì•™ 90%ë§Œ í¬ë¡­
  function cropCenterToCanvas(fullW, fullH, drawCallback) {
    const scale = 0.9;
    const w = Math.floor(fullW * scale);
    const h = Math.floor(fullH * scale);
    const x = Math.floor((fullW - w) / 2);
    const y = Math.floor((fullH - h) / 2);
    drawCallback(x, y, w, h);
  }

  function fillCanvasFromVideoCenter(canvas, ctx) {
    if (!video.videoWidth || !video.videoHeight) {
      canvas.width = 640;
      canvas.height = 360;
      ctx.fillStyle = "black";
      ctx.fillRect(0, 0, canvas.width, canvas.height);
      return;
    }
    const fullW = video.videoWidth;
    const fullH = video.videoHeight;
    cropCenterToCanvas(fullW, fullH, (sx, sy, sw, sh) => {
      canvas.width = sw;
      canvas.height = sh;
      ctx.drawImage(video, sx, sy, sw, sh, 0, 0, sw, sh);
    });
  }

  startCamera();
</script>
</body>
</html>
